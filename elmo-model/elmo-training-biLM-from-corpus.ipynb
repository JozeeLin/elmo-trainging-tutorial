{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/jozee/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#from utils import *\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "import nltk\n",
    "import collections\n",
    "import glob\n",
    "from typing import List\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from nltk.corpus import stopwords\n",
    "from unidecode import unidecode\n",
    "from random import shuffle\n",
    "\n",
    "\n",
    "from tensorflow.python.ops.init_ops import glorot_uniform_initializer\n",
    "\n",
    "DTYPE = 'float32'\n",
    "DTYPE_INT = 'int64'\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "nltk.download('stopwords')\n",
    "english_stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_dir = './data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing function\n",
    "\n",
    "生成vocab.txt vocabulary 文件和corpus.txt tokenized语料库文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clearstring(string):\n",
    "    string = re.sub('[^A-Za-z0-9 ]+', '', string)\n",
    "    string = string.split(' ')\n",
    "    string = filter(None, string)\n",
    "    string = [y.strip() for y in string if y.strip() not in english_stopwords]\n",
    "    string = ' '.join(string)\n",
    "    return string.lower()\n",
    "\n",
    "\n",
    "def separate_dataset(trainset, ratio = 0.5):\n",
    "    datastring = []\n",
    "    datatarget = []\n",
    "    for i in range(len(trainset.data)):\n",
    "        data_ = trainset.data[i].split('\\n')\n",
    "        data_ = list(filter(None, data_))\n",
    "        data_ = random.sample(data_, int(len(data_) * ratio))\n",
    "        for n in range(len(data_)):\n",
    "            data_[n] = clearstring(data_[n])\n",
    "        datastring += data_\n",
    "        for n in range(len(data_)):\n",
    "            datatarget.append(trainset.target[i])\n",
    "    return datastring, datatarget\n",
    "\n",
    "def _genCorpusFile(datasets):\n",
    "    with open(cur_dir+\"/dataset/corpus.txt\",'w') as fout:\n",
    "        fout.write('\\n'.join(datasets))\n",
    "        \n",
    "def _genVocabFile(allWords):\n",
    "    \"\"\"\n",
    "    用我们的训练数据生成一个词汇文件，并加入三个特殊字符\n",
    "    \"\"\"\n",
    "    wordCount = dict(Counter(allWords))  # 统计词频\n",
    "    sortWordCount = dict(sorted(wordCount.items(), key=lambda x: x[1], reverse=True))\n",
    "    words = [item[0] for item in sortWordCount.items()]\n",
    "    allTokens = ['<S>', '</S>', '<UNK>'] + words\n",
    "    with open(cur_dir+\"/dataset/vocab.txt\", 'w') as fout:\n",
    "        fout.write('\\n'.join(allTokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negative', 'positive']\n",
      "10662\n",
      "10662\n"
     ]
    }
   ],
   "source": [
    "trainset = sklearn.datasets.load_files(container_path = cur_dir+'/dataset', encoding = 'UTF-8')\n",
    "trainset.data, trainset.target = separate_dataset(trainset,1.0)\n",
    "print(trainset.target_names)\n",
    "print(len(trainset.data))\n",
    "print(len(trainset.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle(trainset.data)\n",
    "_genCorpusFile(trainset.data)\n",
    "\n",
    "split = (' '.join(trainset.data)).split()\n",
    "_genVocabFile(split)\n",
    "\n",
    "del trainset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bilm相关的数据处理函数\n",
    "\n",
    "定义在:bilm-tf/bilm/data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary(object):\n",
    "    '''\n",
    "    A token vocabulary.  Holds a map from token to ids and provides\n",
    "    a method for encoding text to a sequence of ids.\n",
    "    '''\n",
    "    def __init__(self, filename, validate_file=False):\n",
    "        '''\n",
    "        filename = the vocabulary file.  It is a flat text file with one\n",
    "            (normalized) token per line.  In addition, the file should also\n",
    "            contain the special tokens <S>, </S>, <UNK> (case sensitive).\n",
    "        '''\n",
    "        self._id_to_word = []\n",
    "        self._word_to_id = {}\n",
    "        self._unk = -1\n",
    "        self._bos = -1\n",
    "        self._eos = -1\n",
    "\n",
    "        with open(filename) as f:\n",
    "            idx = 0\n",
    "            for line in f:\n",
    "                word_name = line.strip()\n",
    "                if word_name == '<S>':\n",
    "                    self._bos = idx\n",
    "                elif word_name == '</S>':\n",
    "                    self._eos = idx\n",
    "                elif word_name == '<UNK>':\n",
    "                    self._unk = idx\n",
    "                if word_name == '!!!MAXTERMID':\n",
    "                    continue\n",
    "\n",
    "                self._id_to_word.append(word_name)\n",
    "                self._word_to_id[word_name] = idx\n",
    "                idx += 1\n",
    "\n",
    "        # check to ensure file has special tokens\n",
    "        if validate_file:\n",
    "            if self._bos == -1 or self._eos == -1 or self._unk == -1:\n",
    "                raise ValueError(\"Ensure the vocabulary file has \"\n",
    "                                 \"<S>, </S>, <UNK> tokens\")\n",
    "\n",
    "    @property\n",
    "    def bos(self):\n",
    "        return self._bos\n",
    "\n",
    "    @property\n",
    "    def eos(self):\n",
    "        return self._eos\n",
    "\n",
    "    @property\n",
    "    def unk(self):\n",
    "        return self._unk\n",
    "\n",
    "    @property\n",
    "    def size(self):\n",
    "        return len(self._id_to_word)\n",
    "\n",
    "    def word_to_id(self, word):\n",
    "        if word in self._word_to_id:\n",
    "            return self._word_to_id[word]\n",
    "        return self.unk\n",
    "\n",
    "    def id_to_word(self, cur_id):\n",
    "        return self._id_to_word[cur_id]\n",
    "\n",
    "    def decode(self, cur_ids):\n",
    "        \"\"\"Convert a list of ids to a sentence, with space inserted.\"\"\"\n",
    "        return ' '.join([self.id_to_word(cur_id) for cur_id in cur_ids])\n",
    "\n",
    "    def encode(self, sentence, reverse=False, split=True):\n",
    "        \"\"\"Convert a sentence to a list of ids, with special tokens added.\n",
    "        Sentence is a single string with tokens separated by whitespace.\n",
    "\n",
    "        If reverse, then the sentence is assumed to be reversed, and\n",
    "            this method will swap the BOS/EOS tokens appropriately.\"\"\"\n",
    "\n",
    "        if split:\n",
    "            word_ids = [\n",
    "                self.word_to_id(cur_word) for cur_word in sentence.split()\n",
    "            ]\n",
    "        else:\n",
    "            word_ids = [self.word_to_id(cur_word) for cur_word in sentence]\n",
    "\n",
    "        if reverse:\n",
    "            return np.array([self.eos] + word_ids + [self.bos], dtype=np.int32)\n",
    "        else:\n",
    "            return np.array([self.bos] + word_ids + [self.eos], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UnicodeCharsVocabulary Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnicodeCharsVocabulary(Vocabulary):\n",
    "    \"\"\"Vocabulary containing character-level and word level information.\n",
    "\n",
    "    Has a word vocabulary that is used to lookup word ids and\n",
    "    a character id that is used to map words to arrays of character ids.\n",
    "\n",
    "    The character ids are defined by ord(c) for c in word.encode('utf-8')\n",
    "    This limits the total number of possible char ids to 256.\n",
    "    To this we add 5 additional special ids: begin sentence, end sentence,\n",
    "        begin word, end word and padding.\n",
    "\n",
    "    WARNING: for prediction, we add +1 to the output ids from this\n",
    "    class to create a special padding id (=0).  As a result, we suggest\n",
    "    you use the `Batcher`, `TokenBatcher`, and `LMDataset` classes instead\n",
    "    of this lower level class.  If you are using this lower level class,\n",
    "    then be sure to add the +1 appropriately, otherwise embeddings computed\n",
    "    from the pre-trained model will be useless.\n",
    "    \"\"\"\n",
    "    def __init__(self, filename, max_word_length, **kwargs):\n",
    "        super(UnicodeCharsVocabulary, self).__init__(filename, **kwargs)\n",
    "        self._max_word_length = max_word_length\n",
    "\n",
    "        # char ids 0-255 come from utf-8 encoding bytes\n",
    "        # assign 256-300 to special chars\n",
    "        self.bos_char = 256  # <begin sentence>\n",
    "        self.eos_char = 257  # <end sentence>\n",
    "        self.bow_char = 258  # <begin word>\n",
    "        self.eow_char = 259  # <end word>\n",
    "        self.pad_char = 260 # <padding>\n",
    "\n",
    "        num_words = len(self._id_to_word)\n",
    "\n",
    "        self._word_char_ids = np.zeros([num_words, max_word_length],\n",
    "            dtype=np.int32)\n",
    "\n",
    "        # the charcter representation of the begin/end of sentence characters\n",
    "        def _make_bos_eos(c):\n",
    "            r = np.zeros([self.max_word_length], dtype=np.int32)\n",
    "            r[:] = self.pad_char\n",
    "            r[0] = self.bow_char\n",
    "            r[1] = c\n",
    "            r[2] = self.eow_char\n",
    "            return r\n",
    "        self.bos_chars = _make_bos_eos(self.bos_char)\n",
    "        self.eos_chars = _make_bos_eos(self.eos_char)\n",
    "\n",
    "        for i, word in enumerate(self._id_to_word):\n",
    "            self._word_char_ids[i] = self._convert_word_to_char_ids(word)\n",
    "\n",
    "        self._word_char_ids[self.bos] = self.bos_chars\n",
    "        self._word_char_ids[self.eos] = self.eos_chars\n",
    "        # TODO: properly handle <UNK>\n",
    "\n",
    "    @property\n",
    "    def word_char_ids(self):\n",
    "        return self._word_char_ids\n",
    "\n",
    "    @property\n",
    "    def max_word_length(self):\n",
    "        return self._max_word_length\n",
    "\n",
    "    def _convert_word_to_char_ids(self, word):\n",
    "        code = np.zeros([self.max_word_length], dtype=np.int32)\n",
    "        code[:] = self.pad_char\n",
    "\n",
    "        word_encoded = word.encode('utf-8', 'ignore')[:(self.max_word_length-2)]\n",
    "        code[0] = self.bow_char\n",
    "        for k, chr_id in enumerate(word_encoded, start=1):\n",
    "            code[k] = chr_id\n",
    "        code[len(word_encoded) + 1] = self.eow_char\n",
    "\n",
    "        return code\n",
    "\n",
    "    def word_to_char_ids(self, word):\n",
    "        if word in self._word_to_id:\n",
    "            return self._word_char_ids[self._word_to_id[word]]\n",
    "        else:\n",
    "            return self._convert_word_to_char_ids(word)\n",
    "\n",
    "    def encode_chars(self, sentence, reverse=False, split=True):\n",
    "        '''\n",
    "        Encode the sentence as a white space delimited string of tokens.\n",
    "        '''\n",
    "        if split:\n",
    "            chars_ids = [self.word_to_char_ids(cur_word)\n",
    "                     for cur_word in sentence.split()]\n",
    "        else:\n",
    "            chars_ids = [self.word_to_char_ids(cur_word)\n",
    "                     for cur_word in sentence]\n",
    "        if reverse:\n",
    "            return np.vstack([self.eos_chars] + chars_ids + [self.bos_chars])\n",
    "        else:\n",
    "            return np.vstack([self.bos_chars] + chars_ids + [self.eos_chars])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batcher Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batcher(object):\n",
    "    ''' \n",
    "    Batch sentences of tokenized text into character id matrices.\n",
    "    '''\n",
    "    def __init__(self, lm_vocab_file: str, max_token_length: int):\n",
    "        '''\n",
    "        lm_vocab_file = the language model vocabulary file (one line per\n",
    "            token)\n",
    "        max_token_length = the maximum number of characters in each token\n",
    "        '''\n",
    "        self._lm_vocab = UnicodeCharsVocabulary(\n",
    "            lm_vocab_file, max_token_length\n",
    "        )\n",
    "        self._max_token_length = max_token_length\n",
    "\n",
    "    def batch_sentences(self, sentences: List[List[str]]):\n",
    "        '''\n",
    "        Batch the sentences as character ids\n",
    "        Each sentence is a list of tokens without <s> or </s>, e.g.\n",
    "        [['The', 'first', 'sentence', '.'], ['Second', '.']]\n",
    "        '''\n",
    "        n_sentences = len(sentences)\n",
    "        max_length = max(len(sentence) for sentence in sentences) + 2\n",
    "\n",
    "        X_char_ids = np.zeros(\n",
    "            (n_sentences, max_length, self._max_token_length),\n",
    "            dtype=np.int64\n",
    "        )\n",
    "\n",
    "        for k, sent in enumerate(sentences):\n",
    "            length = len(sent) + 2\n",
    "            char_ids_without_mask = self._lm_vocab.encode_chars(\n",
    "                sent, split=False)\n",
    "            # add one so that 0 is the mask value\n",
    "            X_char_ids[k, :length, :] = char_ids_without_mask + 1\n",
    "\n",
    "        return X_char_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TokenBatcher Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenBatcher(object):\n",
    "    ''' \n",
    "    Batch sentences of tokenized text into token id matrices.\n",
    "    '''\n",
    "    def __init__(self, lm_vocab_file: str):\n",
    "        '''\n",
    "        lm_vocab_file = the language model vocabulary file (one line per\n",
    "            token)\n",
    "        '''\n",
    "        self._lm_vocab = Vocabulary(lm_vocab_file)\n",
    "\n",
    "    def batch_sentences(self, sentences: List[List[str]]):\n",
    "        '''\n",
    "        Batch the sentences as character ids\n",
    "        Each sentence is a list of tokens without <s> or </s>, e.g.\n",
    "        [['The', 'first', 'sentence', '.'], ['Second', '.']]\n",
    "        '''\n",
    "        n_sentences = len(sentences)\n",
    "        max_length = max(len(sentence) for sentence in sentences) + 2\n",
    "\n",
    "        X_ids = np.zeros((n_sentences, max_length), dtype=np.int64)\n",
    "\n",
    "        for k, sent in enumerate(sentences):\n",
    "            length = len(sent) + 2\n",
    "            ids_without_mask = self._lm_vocab.encode(sent, split=False)\n",
    "            # add one so that 0 is the mask value\n",
    "            X_ids[k, :length] = ids_without_mask + 1\n",
    "\n",
    "        return X_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \\_get\\_batch function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### for training\n",
    "def _get_batch(generator, batch_size, num_steps, max_word_length):\n",
    "    \"\"\"Read batches of input.\"\"\"\n",
    "    cur_stream = [None] * batch_size\n",
    "\n",
    "    no_more_data = False\n",
    "    while True:\n",
    "        inputs = np.zeros([batch_size, num_steps], np.int32)\n",
    "        if max_word_length is not None:\n",
    "            char_inputs = np.zeros([batch_size, num_steps, max_word_length],\n",
    "                                np.int32)\n",
    "        else:\n",
    "            char_inputs = None\n",
    "        targets = np.zeros([batch_size, num_steps], np.int32)\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            cur_pos = 0\n",
    "\n",
    "            while cur_pos < num_steps:\n",
    "                if cur_stream[i] is None or len(cur_stream[i][0]) <= 1:\n",
    "                    try:\n",
    "                        cur_stream[i] = list(next(generator))\n",
    "                    except StopIteration:\n",
    "                        # No more data, exhaust current streams and quit\n",
    "                        no_more_data = True\n",
    "                        break\n",
    "\n",
    "                how_many = min(len(cur_stream[i][0]) - 1, num_steps - cur_pos)\n",
    "                next_pos = cur_pos + how_many\n",
    "\n",
    "                inputs[i, cur_pos:next_pos] = cur_stream[i][0][:how_many]\n",
    "                if max_word_length is not None:\n",
    "                    char_inputs[i, cur_pos:next_pos] = cur_stream[i][1][\n",
    "                                                                    :how_many]\n",
    "                targets[i, cur_pos:next_pos] = cur_stream[i][0][1:how_many+1]\n",
    "\n",
    "                cur_pos = next_pos\n",
    "\n",
    "                cur_stream[i][0] = cur_stream[i][0][how_many:]\n",
    "                if max_word_length is not None:\n",
    "                    cur_stream[i][1] = cur_stream[i][1][how_many:]\n",
    "\n",
    "        if no_more_data:\n",
    "            # There is no more data.  Note: this will not return data\n",
    "            # for the incomplete batch\n",
    "            break\n",
    "\n",
    "        X = {'token_ids': inputs, 'tokens_characters': char_inputs,\n",
    "                 'next_token_id': targets}\n",
    "\n",
    "        yield X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LMDataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LMDataset(object):\n",
    "    \"\"\"\n",
    "    Hold a language model dataset.\n",
    "\n",
    "    A dataset is a list of tokenized files.  Each file contains one sentence\n",
    "        per line.  Each sentence is pre-tokenized and white space joined.\n",
    "    \"\"\"\n",
    "    def __init__(self, filepattern, vocab, reverse=False, test=False,\n",
    "                 shuffle_on_load=False):\n",
    "        '''\n",
    "        filepattern = a glob string that specifies the list of files.\n",
    "        vocab = an instance of Vocabulary or UnicodeCharsVocabulary\n",
    "        reverse = if True, then iterate over tokens in each sentence in reverse\n",
    "        test = if True, then iterate through all data once then stop.\n",
    "            Otherwise, iterate forever.\n",
    "        shuffle_on_load = if True, then shuffle the sentences after loading.\n",
    "        '''\n",
    "        self._vocab = vocab\n",
    "        self._all_shards = glob.glob(filepattern)\n",
    "        print('Found %d shards at %s' % (len(self._all_shards), filepattern))\n",
    "        self._shards_to_choose = []\n",
    "\n",
    "        self._reverse = reverse\n",
    "        self._test = test\n",
    "        self._shuffle_on_load = shuffle_on_load\n",
    "        self._use_char_inputs = hasattr(vocab, 'encode_chars')\n",
    "\n",
    "        self._ids = self._load_random_shard()\n",
    "\n",
    "    def _choose_random_shard(self):\n",
    "        if len(self._shards_to_choose) == 0:\n",
    "            self._shards_to_choose = list(self._all_shards)\n",
    "            random.shuffle(self._shards_to_choose)\n",
    "        shard_name = self._shards_to_choose.pop()\n",
    "        return shard_name\n",
    "\n",
    "    def _load_random_shard(self):\n",
    "        \"\"\"Randomly select a file and read it.\"\"\"\n",
    "        if self._test:\n",
    "            if len(self._all_shards) == 0:\n",
    "                # we've loaded all the data\n",
    "                # this will propogate up to the generator in get_batch\n",
    "                # and stop iterating\n",
    "                raise StopIteration\n",
    "            else:\n",
    "                shard_name = self._all_shards.pop()\n",
    "        else:\n",
    "            # just pick a random shard\n",
    "            shard_name = self._choose_random_shard()\n",
    "\n",
    "        ids = self._load_shard(shard_name)\n",
    "        self._i = 0\n",
    "        self._nids = len(ids)\n",
    "        return ids\n",
    "\n",
    "    def _load_shard(self, shard_name):\n",
    "        \"\"\"Read one file and convert to ids.\n",
    "\n",
    "        Args:\n",
    "            shard_name: file path.\n",
    "\n",
    "        Returns:\n",
    "            list of (id, char_id) tuples.\n",
    "        \"\"\"\n",
    "        print('Loading data from: %s' % shard_name)\n",
    "        with open(shard_name) as f:\n",
    "            sentences_raw = f.readlines()\n",
    "\n",
    "        if self._reverse:\n",
    "            sentences = []\n",
    "            for sentence in sentences_raw:\n",
    "                splitted = sentence.split()\n",
    "                splitted.reverse()\n",
    "                sentences.append(' '.join(splitted))\n",
    "        else:\n",
    "            sentences = sentences_raw\n",
    "\n",
    "        if self._shuffle_on_load:\n",
    "            random.shuffle(sentences)\n",
    "\n",
    "        ids = [self.vocab.encode(sentence, self._reverse)\n",
    "               for sentence in sentences]\n",
    "        if self._use_char_inputs:\n",
    "            chars_ids = [self.vocab.encode_chars(sentence, self._reverse)\n",
    "                     for sentence in sentences]\n",
    "        else:\n",
    "            chars_ids = [None] * len(ids)\n",
    "\n",
    "        print('Loaded %d sentences.' % len(ids))\n",
    "        print('Finished loading')\n",
    "        return list(zip(ids, chars_ids))\n",
    "\n",
    "    def get_sentence(self):\n",
    "        while True:\n",
    "            if self._i == self._nids:\n",
    "                self._ids = self._load_random_shard()\n",
    "            ret = self._ids[self._i]\n",
    "            self._i += 1\n",
    "            yield ret\n",
    "\n",
    "    @property\n",
    "    def max_word_length(self):\n",
    "        if self._use_char_inputs:\n",
    "            return self._vocab.max_word_length\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def iter_batches(self, batch_size, num_steps):\n",
    "        for X in _get_batch(self.get_sentence(), batch_size, num_steps,\n",
    "                           self.max_word_length):\n",
    "\n",
    "            # token_ids = (batch_size, num_steps)\n",
    "            # char_inputs = (batch_size, num_steps, 50) of character ids\n",
    "            # targets = word ID of next word (batch_size, num_steps)\n",
    "            yield X\n",
    "\n",
    "    @property\n",
    "    def vocab(self):\n",
    "        return self._vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BidirectionalLMDataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BidirectionalLMDataset(object):\n",
    "    def __init__(self, filepattern, vocab, test=False, shuffle_on_load=False):\n",
    "        '''\n",
    "        bidirectional version of LMDataset\n",
    "        '''\n",
    "        self._data_forward = LMDataset(\n",
    "            filepattern, vocab, reverse=False, test=test,\n",
    "            shuffle_on_load=shuffle_on_load)\n",
    "        self._data_reverse = LMDataset(\n",
    "            filepattern, vocab, reverse=True, test=test,\n",
    "            shuffle_on_load=shuffle_on_load)\n",
    "\n",
    "    def iter_batches(self, batch_size, num_steps):\n",
    "        max_word_length = self._data_forward.max_word_length\n",
    "\n",
    "        for X, Xr in zip(\n",
    "            _get_batch(self._data_forward.get_sentence(), batch_size,\n",
    "                      num_steps, max_word_length),\n",
    "            _get_batch(self._data_reverse.get_sentence(), batch_size,\n",
    "                      num_steps, max_word_length)\n",
    "            ):\n",
    "\n",
    "            for k, v in Xr.items():\n",
    "                X[k + '_reverse'] = v\n",
    "\n",
    "            yield X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## InvalidNumberOfCharacters Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvalidNumberOfCharacters(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LanguageModel Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_variable_summary():\n",
    "    import pprint\n",
    "    variables = sorted([[v.name, v.get_shape()] for v in tf.global_variables()])\n",
    "    pprint.pprint(variables)\n",
    "\n",
    "\n",
    "class LanguageModel(object):\n",
    "    '''\n",
    "    A class to build the tensorflow computational graph for NLMs\n",
    "\n",
    "    All hyperparameters and model configuration is specified in a dictionary\n",
    "    of 'options'.\n",
    "\n",
    "    is_training is a boolean used to control behavior of dropout layers\n",
    "        and softmax.  Set to False for testing.\n",
    "\n",
    "    The LSTM cell is controlled by the 'lstm' key in options\n",
    "    Here is an example:\n",
    "\n",
    "     'lstm': {\n",
    "      'cell_clip': 5,\n",
    "      'dim': 4096,\n",
    "      'n_layers': 2,\n",
    "      'proj_clip': 5,\n",
    "      'projection_dim': 512,\n",
    "      'use_skip_connections': True},\n",
    "\n",
    "        'projection_dim' is assumed token embedding size and LSTM output size.\n",
    "        'dim' is the hidden state size.\n",
    "        Set 'dim' == 'projection_dim' to skip a projection layer.\n",
    "    '''\n",
    "    def __init__(self, options, is_training):\n",
    "        self.options = options\n",
    "        self.is_training = is_training\n",
    "        self.bidirectional = options.get('bidirectional', False)\n",
    "\n",
    "        # use word or char inputs?\n",
    "        self.char_inputs = 'char_cnn' in self.options\n",
    "\n",
    "        # for the loss function\n",
    "        self.share_embedding_softmax = options.get(\n",
    "            'share_embedding_softmax', False)\n",
    "        if self.char_inputs and self.share_embedding_softmax:\n",
    "            raise ValueError(\"Sharing softmax and embedding weights requires \"\n",
    "                             \"word input\")\n",
    "\n",
    "        self.sample_softmax = options.get('sample_softmax', True)\n",
    "\n",
    "        self._build()\n",
    "\n",
    "    def _build_word_embeddings(self):\n",
    "        n_tokens_vocab = self.options['n_tokens_vocab']\n",
    "        batch_size = self.options['batch_size']\n",
    "        unroll_steps = self.options['unroll_steps']\n",
    "\n",
    "        # LSTM options\n",
    "        projection_dim = self.options['lstm']['projection_dim']\n",
    "\n",
    "        # the input token_ids and word embeddings\n",
    "        self.token_ids = tf.placeholder(DTYPE_INT,\n",
    "                               shape=(batch_size, unroll_steps),\n",
    "                               name='token_ids')\n",
    "        # the word embeddings\n",
    "        with tf.device(\"/cpu:0\"):\n",
    "            self.embedding_weights = tf.get_variable(\n",
    "                \"embedding\", [n_tokens_vocab, projection_dim],\n",
    "                dtype=DTYPE,\n",
    "            )\n",
    "            self.embedding = tf.nn.embedding_lookup(self.embedding_weights,\n",
    "                                                self.token_ids)\n",
    "\n",
    "        # if a bidirectional LM then make placeholders for reverse\n",
    "        # model and embeddings\n",
    "        if self.bidirectional:\n",
    "            self.token_ids_reverse = tf.placeholder(DTYPE_INT,\n",
    "                               shape=(batch_size, unroll_steps),\n",
    "                               name='token_ids_reverse')\n",
    "            with tf.device(\"/cpu:0\"):\n",
    "                self.embedding_reverse = tf.nn.embedding_lookup(\n",
    "                    self.embedding_weights, self.token_ids_reverse)\n",
    "\n",
    "    def _build_word_char_embeddings(self):\n",
    "        '''\n",
    "        options contains key 'char_cnn': {\n",
    "\n",
    "        'n_characters': 262,\n",
    "\n",
    "        # includes the start / end characters\n",
    "        'max_characters_per_token': 50,\n",
    "\n",
    "        'filters': [\n",
    "            [1, 32],\n",
    "            [2, 32],\n",
    "            [3, 64],\n",
    "            [4, 128],\n",
    "            [5, 256],\n",
    "            [6, 512],\n",
    "            [7, 512]\n",
    "        ],\n",
    "        'activation': 'tanh',\n",
    "\n",
    "        # for the character embedding\n",
    "        'embedding': {'dim': 16}\n",
    "\n",
    "        # for highway layers\n",
    "        # if omitted, then no highway layers\n",
    "        'n_highway': 2,\n",
    "        }\n",
    "        '''\n",
    "        batch_size = self.options['batch_size']\n",
    "        unroll_steps = self.options['unroll_steps']\n",
    "        projection_dim = self.options['lstm']['projection_dim']\n",
    "    \n",
    "        cnn_options = self.options['char_cnn']\n",
    "        filters = cnn_options['filters']\n",
    "        n_filters = sum(f[1] for f in filters)\n",
    "        max_chars = cnn_options['max_characters_per_token']\n",
    "        char_embed_dim = cnn_options['embedding']['dim']\n",
    "        n_chars = cnn_options['n_characters']\n",
    "        if n_chars != 261:\n",
    "            raise InvalidNumberOfCharacters(\n",
    "                    \"Set n_characters=261 for training see the README.md\"\n",
    "            )\n",
    "        if cnn_options['activation'] == 'tanh':\n",
    "            activation = tf.nn.tanh\n",
    "        elif cnn_options['activation'] == 'relu':\n",
    "            activation = tf.nn.relu\n",
    "\n",
    "        # the input character ids \n",
    "        self.tokens_characters = tf.placeholder(DTYPE_INT,\n",
    "                                   shape=(batch_size, unroll_steps, max_chars),\n",
    "                                   name='tokens_characters')\n",
    "        # the character embeddings\n",
    "        with tf.device(\"/cpu:0\"):\n",
    "            self.embedding_weights = tf.get_variable(\n",
    "                    \"char_embed\", [n_chars, char_embed_dim],\n",
    "                    dtype=DTYPE,\n",
    "                    initializer=tf.random_uniform_initializer(-1.0, 1.0)\n",
    "            )\n",
    "            # shape (batch_size, unroll_steps, max_chars, embed_dim)\n",
    "            self.char_embedding = tf.nn.embedding_lookup(self.embedding_weights,\n",
    "                                                    self.tokens_characters)\n",
    "\n",
    "            if self.bidirectional:\n",
    "                self.tokens_characters_reverse = tf.placeholder(DTYPE_INT,\n",
    "                                   shape=(batch_size, unroll_steps, max_chars),\n",
    "                                   name='tokens_characters_reverse')\n",
    "                self.char_embedding_reverse = tf.nn.embedding_lookup(\n",
    "                    self.embedding_weights, self.tokens_characters_reverse)\n",
    "\n",
    "\n",
    "        # the convolutions\n",
    "        def make_convolutions(inp, reuse):\n",
    "            with tf.variable_scope('CNN', reuse=reuse) as scope:\n",
    "                convolutions = []\n",
    "                for i, (width, num) in enumerate(filters):\n",
    "                    if cnn_options['activation'] == 'relu':\n",
    "                        # He initialization for ReLU activation\n",
    "                        # with char embeddings init between -1 and 1\n",
    "                        #w_init = tf.random_normal_initializer(\n",
    "                        #    mean=0.0,\n",
    "                        #    stddev=np.sqrt(2.0 / (width * char_embed_dim))\n",
    "                        #)\n",
    "\n",
    "                        # Kim et al 2015, +/- 0.05\n",
    "                        w_init = tf.random_uniform_initializer(\n",
    "                            minval=-0.05, maxval=0.05)\n",
    "                    elif cnn_options['activation'] == 'tanh':\n",
    "                        # glorot init\n",
    "                        w_init = tf.random_normal_initializer(\n",
    "                            mean=0.0,\n",
    "                            stddev=np.sqrt(1.0 / (width * char_embed_dim))\n",
    "                        )\n",
    "                    w = tf.get_variable(\n",
    "                        \"W_cnn_%s\" % i,\n",
    "                        [1, width, char_embed_dim, num],\n",
    "                        initializer=w_init,\n",
    "                        dtype=DTYPE)\n",
    "                    b = tf.get_variable(\n",
    "                        \"b_cnn_%s\" % i, [num], dtype=DTYPE,\n",
    "                        initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "                    conv = tf.nn.conv2d(\n",
    "                            inp, w,\n",
    "                            strides=[1, 1, 1, 1],\n",
    "                            padding=\"VALID\") + b\n",
    "                    # now max pool\n",
    "                    conv = tf.nn.max_pool(\n",
    "                            conv, [1, 1, max_chars-width+1, 1],\n",
    "                            [1, 1, 1, 1], 'VALID')\n",
    "\n",
    "                    # activation\n",
    "                    conv = activation(conv)\n",
    "                    conv = tf.squeeze(conv, squeeze_dims=[2])\n",
    "\n",
    "                    convolutions.append(conv)\n",
    "\n",
    "            return tf.concat(convolutions, 2)\n",
    "\n",
    "        # for first model, this is False, for others it's True\n",
    "        reuse = tf.get_variable_scope().reuse\n",
    "        embedding = make_convolutions(self.char_embedding, reuse)\n",
    "\n",
    "        self.token_embedding_layers = [embedding]\n",
    "\n",
    "        if self.bidirectional:\n",
    "            # re-use the CNN weights from forward pass\n",
    "            embedding_reverse = make_convolutions(\n",
    "                self.char_embedding_reverse, True)\n",
    "\n",
    "        # for highway and projection layers:\n",
    "        #   reshape from (batch_size, n_tokens, dim) to\n",
    "        n_highway = cnn_options.get('n_highway')\n",
    "        use_highway = n_highway is not None and n_highway > 0\n",
    "        use_proj = n_filters != projection_dim\n",
    "\n",
    "        if use_highway or use_proj:\n",
    "            embedding = tf.reshape(embedding, [-1, n_filters])\n",
    "            if self.bidirectional:\n",
    "                embedding_reverse = tf.reshape(embedding_reverse,\n",
    "                    [-1, n_filters])\n",
    "\n",
    "        # set up weights for projection\n",
    "        if use_proj:\n",
    "            assert n_filters > projection_dim\n",
    "            with tf.variable_scope('CNN_proj') as scope:\n",
    "                    W_proj_cnn = tf.get_variable(\n",
    "                        \"W_proj\", [n_filters, projection_dim],\n",
    "                        initializer=tf.random_normal_initializer(\n",
    "                            mean=0.0, stddev=np.sqrt(1.0 / n_filters)),\n",
    "                        dtype=DTYPE)\n",
    "                    b_proj_cnn = tf.get_variable(\n",
    "                        \"b_proj\", [projection_dim],\n",
    "                        initializer=tf.constant_initializer(0.0),\n",
    "                        dtype=DTYPE)\n",
    "\n",
    "        # apply highways layers\n",
    "        def high(x, ww_carry, bb_carry, ww_tr, bb_tr):\n",
    "            carry_gate = tf.nn.sigmoid(tf.matmul(x, ww_carry) + bb_carry)\n",
    "            transform_gate = tf.nn.relu(tf.matmul(x, ww_tr) + bb_tr)\n",
    "            return carry_gate * transform_gate + (1.0 - carry_gate) * x\n",
    "\n",
    "        if use_highway:\n",
    "            highway_dim = n_filters\n",
    "\n",
    "            for i in range(n_highway):\n",
    "                with tf.variable_scope('CNN_high_%s' % i) as scope:\n",
    "                    W_carry = tf.get_variable(\n",
    "                        'W_carry', [highway_dim, highway_dim],\n",
    "                        # glorit init\n",
    "                        initializer=tf.random_normal_initializer(\n",
    "                            mean=0.0, stddev=np.sqrt(1.0 / highway_dim)),\n",
    "                        dtype=DTYPE)\n",
    "                    b_carry = tf.get_variable(\n",
    "                        'b_carry', [highway_dim],\n",
    "                        initializer=tf.constant_initializer(-2.0),\n",
    "                        dtype=DTYPE)\n",
    "                    W_transform = tf.get_variable(\n",
    "                        'W_transform', [highway_dim, highway_dim],\n",
    "                        initializer=tf.random_normal_initializer(\n",
    "                            mean=0.0, stddev=np.sqrt(1.0 / highway_dim)),\n",
    "                        dtype=DTYPE)\n",
    "                    b_transform = tf.get_variable(\n",
    "                        'b_transform', [highway_dim],\n",
    "                        initializer=tf.constant_initializer(0.0),\n",
    "                        dtype=DTYPE)\n",
    "\n",
    "                embedding = high(embedding, W_carry, b_carry,\n",
    "                                 W_transform, b_transform)\n",
    "                if self.bidirectional:\n",
    "                    embedding_reverse = high(embedding_reverse,\n",
    "                                             W_carry, b_carry,\n",
    "                                             W_transform, b_transform)\n",
    "                self.token_embedding_layers.append(\n",
    "                    tf.reshape(embedding, \n",
    "                        [batch_size, unroll_steps, highway_dim])\n",
    "                )\n",
    "\n",
    "        # finally project down to projection dim if needed\n",
    "        if use_proj:\n",
    "            embedding = tf.matmul(embedding, W_proj_cnn) + b_proj_cnn\n",
    "            if self.bidirectional:\n",
    "                embedding_reverse = tf.matmul(embedding_reverse, W_proj_cnn) \\\n",
    "                    + b_proj_cnn\n",
    "            self.token_embedding_layers.append(\n",
    "                tf.reshape(embedding,\n",
    "                        [batch_size, unroll_steps, projection_dim])\n",
    "            )\n",
    "\n",
    "        # reshape back to (batch_size, tokens, dim)\n",
    "        if use_highway or use_proj:\n",
    "            shp = [batch_size, unroll_steps, projection_dim]\n",
    "            embedding = tf.reshape(embedding, shp)\n",
    "            if self.bidirectional:\n",
    "                embedding_reverse = tf.reshape(embedding_reverse, shp)\n",
    "\n",
    "        # at last assign attributes for remainder of the model\n",
    "        self.embedding = embedding\n",
    "        if self.bidirectional:\n",
    "            self.embedding_reverse = embedding_reverse\n",
    "\n",
    "    def _build(self):\n",
    "        # size of input options\n",
    "        n_tokens_vocab = self.options['n_tokens_vocab']\n",
    "        batch_size = self.options['batch_size']\n",
    "        unroll_steps = self.options['unroll_steps']\n",
    "\n",
    "        # LSTM options\n",
    "        lstm_dim = self.options['lstm']['dim']\n",
    "        projection_dim = self.options['lstm']['projection_dim']\n",
    "        n_lstm_layers = self.options['lstm'].get('n_layers', 1)\n",
    "        dropout = self.options['dropout']\n",
    "        keep_prob = 1.0 - dropout\n",
    "\n",
    "        if self.char_inputs:\n",
    "            self._build_word_char_embeddings()\n",
    "        else:\n",
    "            self._build_word_embeddings()\n",
    "\n",
    "        # now the LSTMs\n",
    "        # these will collect the initial states for the forward\n",
    "        #   (and reverse LSTMs if we are doing bidirectional)\n",
    "        self.init_lstm_state = []\n",
    "        self.final_lstm_state = []\n",
    "\n",
    "        # get the LSTM inputs\n",
    "        if self.bidirectional:\n",
    "            lstm_inputs = [self.embedding, self.embedding_reverse]\n",
    "        else:\n",
    "            lstm_inputs = [self.embedding]\n",
    "\n",
    "        # now compute the LSTM outputs\n",
    "        cell_clip = self.options['lstm'].get('cell_clip')\n",
    "        proj_clip = self.options['lstm'].get('proj_clip')\n",
    "\n",
    "        use_skip_connections = self.options['lstm'].get(\n",
    "                                            'use_skip_connections')\n",
    "        if use_skip_connections:\n",
    "            print(\"USING SKIP CONNECTIONS\")\n",
    "\n",
    "        lstm_outputs = []\n",
    "        for lstm_num, lstm_input in enumerate(lstm_inputs):\n",
    "            lstm_cells = []\n",
    "            for i in range(n_lstm_layers):\n",
    "                if projection_dim < lstm_dim:\n",
    "                    # are projecting down output\n",
    "                    lstm_cell = tf.nn.rnn_cell.LSTMCell(\n",
    "                        lstm_dim, num_proj=projection_dim,\n",
    "                        cell_clip=cell_clip, proj_clip=proj_clip)\n",
    "                else:\n",
    "                    lstm_cell = tf.nn.rnn_cell.LSTMCell(\n",
    "                        lstm_dim,\n",
    "                        cell_clip=cell_clip, proj_clip=proj_clip)\n",
    "\n",
    "                if use_skip_connections:\n",
    "                    # ResidualWrapper adds inputs to outputs\n",
    "                    if i == 0:\n",
    "                        # don't add skip connection from token embedding to\n",
    "                        # 1st layer output\n",
    "                        pass\n",
    "                    else:\n",
    "                        # add a skip connection\n",
    "                        lstm_cell = tf.nn.rnn_cell.ResidualWrapper(lstm_cell)\n",
    "\n",
    "                # add dropout\n",
    "                if self.is_training:\n",
    "                    lstm_cell = tf.nn.rnn_cell.DropoutWrapper(lstm_cell,\n",
    "                        input_keep_prob=keep_prob)\n",
    "\n",
    "                lstm_cells.append(lstm_cell)\n",
    "\n",
    "            if n_lstm_layers > 1:\n",
    "                lstm_cell = tf.nn.rnn_cell.MultiRNNCell(lstm_cells)\n",
    "            else:\n",
    "                lstm_cell = lstm_cells[0]\n",
    "\n",
    "            with tf.control_dependencies([lstm_input]):\n",
    "                self.init_lstm_state.append(\n",
    "                    lstm_cell.zero_state(batch_size, DTYPE))\n",
    "                # NOTE: this variable scope is for backward compatibility\n",
    "                # with existing models...\n",
    "                if self.bidirectional:\n",
    "                    with tf.variable_scope('RNN_%s' % lstm_num):\n",
    "                        _lstm_output_unpacked, final_state = tf.nn.static_rnn(\n",
    "                            lstm_cell,\n",
    "                            tf.unstack(lstm_input, axis=1),\n",
    "                            initial_state=self.init_lstm_state[-1])\n",
    "                else:\n",
    "                    _lstm_output_unpacked, final_state = tf.nn.static_rnn(\n",
    "                        lstm_cell,\n",
    "                        tf.unstack(lstm_input, axis=1),\n",
    "                        initial_state=self.init_lstm_state[-1])\n",
    "                self.final_lstm_state.append(final_state)\n",
    "\n",
    "            # (batch_size * unroll_steps, 512)\n",
    "            lstm_output_flat = tf.reshape(\n",
    "                tf.stack(_lstm_output_unpacked, axis=1), [-1, projection_dim])\n",
    "            if self.is_training:\n",
    "                # add dropout to output\n",
    "                lstm_output_flat = tf.nn.dropout(lstm_output_flat,\n",
    "                    keep_prob)\n",
    "            tf.add_to_collection('lstm_output_embeddings',\n",
    "                _lstm_output_unpacked)\n",
    "\n",
    "            lstm_outputs.append(lstm_output_flat)\n",
    "\n",
    "        self._build_loss(lstm_outputs)\n",
    "\n",
    "    def _build_loss(self, lstm_outputs):\n",
    "        '''\n",
    "        Create:\n",
    "            self.total_loss: total loss op for training\n",
    "            self.softmax_W, softmax_b: the softmax variables\n",
    "            self.next_token_id / _reverse: placeholders for gold input\n",
    "\n",
    "        '''\n",
    "        batch_size = self.options['batch_size']\n",
    "        unroll_steps = self.options['unroll_steps']\n",
    "\n",
    "        n_tokens_vocab = self.options['n_tokens_vocab']\n",
    "\n",
    "        # DEFINE next_token_id and *_reverse placeholders for the gold input\n",
    "        def _get_next_token_placeholders(suffix):\n",
    "            name = 'next_token_id' + suffix\n",
    "            id_placeholder = tf.placeholder(DTYPE_INT,\n",
    "                                   shape=(batch_size, unroll_steps),\n",
    "                                   name=name)\n",
    "            return id_placeholder\n",
    "\n",
    "        # get the window and weight placeholders\n",
    "        self.next_token_id = _get_next_token_placeholders('')\n",
    "        if self.bidirectional:\n",
    "            self.next_token_id_reverse = _get_next_token_placeholders(\n",
    "                '_reverse')\n",
    "\n",
    "        # DEFINE THE SOFTMAX VARIABLES\n",
    "        # get the dimension of the softmax weights\n",
    "        # softmax dimension is the size of the output projection_dim\n",
    "        softmax_dim = self.options['lstm']['projection_dim']\n",
    "\n",
    "        # the output softmax variables -- they are shared if bidirectional\n",
    "        if self.share_embedding_softmax:\n",
    "            # softmax_W is just the embedding layer\n",
    "            self.softmax_W = self.embedding_weights\n",
    "\n",
    "        with tf.variable_scope('softmax'), tf.device('/cpu:0'):\n",
    "            # Glorit init (std=(1.0 / sqrt(fan_in))\n",
    "            softmax_init = tf.random_normal_initializer(0.0,\n",
    "                1.0 / np.sqrt(softmax_dim))\n",
    "            if not self.share_embedding_softmax:\n",
    "                self.softmax_W = tf.get_variable(\n",
    "                    'W', [n_tokens_vocab, softmax_dim],\n",
    "                    dtype=DTYPE,\n",
    "                    initializer=softmax_init\n",
    "                )\n",
    "            self.softmax_b = tf.get_variable(\n",
    "                'b', [n_tokens_vocab],\n",
    "                dtype=DTYPE,\n",
    "                initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "        # now calculate losses\n",
    "        # loss for each direction of the LSTM\n",
    "        self.individual_losses = []\n",
    "\n",
    "        if self.bidirectional:\n",
    "            next_ids = [self.next_token_id, self.next_token_id_reverse]\n",
    "        else:\n",
    "            next_ids = [self.next_token_id]\n",
    "\n",
    "        for id_placeholder, lstm_output_flat in zip(next_ids, lstm_outputs):\n",
    "            # flatten the LSTM output and next token id gold to shape:\n",
    "            # (batch_size * unroll_steps, softmax_dim)\n",
    "            # Flatten and reshape the token_id placeholders\n",
    "            next_token_id_flat = tf.reshape(id_placeholder, [-1, 1])\n",
    "\n",
    "            with tf.control_dependencies([lstm_output_flat]):\n",
    "                if self.is_training and self.sample_softmax:\n",
    "                    losses = tf.nn.sampled_softmax_loss(\n",
    "                                   self.softmax_W, self.softmax_b,\n",
    "                                   next_token_id_flat, lstm_output_flat,\n",
    "                                   self.options['n_negative_samples_batch'],\n",
    "                                   self.options['n_tokens_vocab'],\n",
    "                                   num_true=1)\n",
    "\n",
    "                else:\n",
    "                    # get the full softmax loss\n",
    "                    output_scores = tf.matmul(\n",
    "                        lstm_output_flat,\n",
    "                        tf.transpose(self.softmax_W)\n",
    "                    ) + self.softmax_b\n",
    "                    # NOTE: tf.nn.sparse_softmax_cross_entropy_with_logits\n",
    "                    #   expects unnormalized output since it performs the\n",
    "                    #   softmax internally\n",
    "                    losses = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                        logits=output_scores,\n",
    "                        labels=tf.squeeze(next_token_id_flat, squeeze_dims=[1])\n",
    "                    )\n",
    "\n",
    "            self.individual_losses.append(tf.reduce_mean(losses))\n",
    "\n",
    "        # now make the total loss -- it's the mean of the individual losses\n",
    "        if self.bidirectional:\n",
    "            self.total_loss = 0.5 * (self.individual_losses[0]\n",
    "                                    + self.individual_losses[1])\n",
    "        else:\n",
    "            self.total_loss = self.individual_losses[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dump_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_options_latest_checkpoint(tf_save_dir):\n",
    "    options_file = os.path.join(tf_save_dir, 'options.json')\n",
    "    ckpt_file = tf.train.latest_checkpoint(tf_save_dir)\n",
    "\n",
    "    with open(options_file, 'r') as fin:\n",
    "        options = json.load(fin)\n",
    "\n",
    "    return options, ckpt_file\n",
    "\n",
    "\n",
    "def load_vocab(vocab_file, max_word_length=None):\n",
    "    if max_word_length:\n",
    "        return UnicodeCharsVocabulary(vocab_file, max_word_length,\n",
    "                                      validate_file=True)\n",
    "    else:\n",
    "        return Vocabulary(vocab_file, validate_file=True)\n",
    "\n",
    "\n",
    "def dump_weights(tf_save_dir, outfile):\n",
    "    '''\n",
    "    Dump the trained weights from a model to a HDF5 file.\n",
    "    '''\n",
    "    import h5py\n",
    "\n",
    "    def _get_outname(tf_name):\n",
    "        outname = re.sub(':0$', '', tf_name)\n",
    "        outname = outname.lstrip('lm/')\n",
    "        outname = re.sub('/rnn/', '/RNN/', outname)\n",
    "        outname = re.sub('/multi_rnn_cell/', '/MultiRNNCell/', outname)\n",
    "        outname = re.sub('/cell_', '/Cell', outname)\n",
    "        outname = re.sub('/lstm_cell/', '/LSTMCell/', outname)\n",
    "        if '/RNN/' in outname:\n",
    "            if 'projection' in outname:\n",
    "                outname = re.sub('projection/kernel', 'W_P_0', outname)\n",
    "            else:\n",
    "                outname = re.sub('/kernel', '/W_0', outname)\n",
    "                outname = re.sub('/bias', '/B', outname)\n",
    "        return outname\n",
    "\n",
    "    options, ckpt_file = load_options_latest_checkpoint(tf_save_dir)\n",
    "\n",
    "    config = tf.ConfigProto(allow_soft_placement=True)\n",
    "    with tf.Session(config=config) as sess:\n",
    "        with tf.variable_scope('lm'):\n",
    "            model = LanguageModel(options, False)\n",
    "            # we use the \"Saver\" class to load the variables\n",
    "            loader = tf.train.Saver()\n",
    "            loader.restore(sess, ckpt_file)\n",
    "\n",
    "        with h5py.File(outfile, 'w') as fout:\n",
    "            for v in tf.trainable_variables():\n",
    "                if v.name.find('softmax') >= 0:\n",
    "                    # don't dump these\n",
    "                    continue\n",
    "                outname = _get_outname(v.name)\n",
    "                print(\"Saving variable {0} with name {1}\".format(\n",
    "                    v.name, outname))\n",
    "                shape = v.get_shape().as_list()\n",
    "                dset = fout.create_dataset(outname, shape, dtype='float32')\n",
    "                values = sess.run([v])[0]\n",
    "                dset[...] = values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_gradients(tower_grads, batch_size, options):\n",
    "    # calculate average gradient for each shared variable across all GPUs\n",
    "    average_grads = []\n",
    "    for grad_and_vars in zip(*tower_grads):\n",
    "        # Note that each grad_and_vars looks like the following:\n",
    "        #   ((grad0_gpu0, var0_gpu0), ... , (grad0_gpuN, var0_gpuN))\n",
    "        # We need to average the gradients across each GPU.\n",
    "\n",
    "        g0, v0 = grad_and_vars[0]\n",
    "\n",
    "        if g0 is None:\n",
    "            # no gradient for this variable, skip it\n",
    "            average_grads.append((g0, v0))\n",
    "            continue\n",
    "\n",
    "        if isinstance(g0, tf.IndexedSlices):\n",
    "            # If the gradient is type IndexedSlices then this is a sparse\n",
    "            #   gradient with attributes indices and values.\n",
    "            # To average, need to concat them individually then create\n",
    "            #   a new IndexedSlices object.\n",
    "            indices = []\n",
    "            values = []\n",
    "            for g, v in grad_and_vars:\n",
    "                indices.append(g.indices)\n",
    "                values.append(g.values)\n",
    "            all_indices = tf.concat(indices, 0)\n",
    "            avg_values = tf.concat(values, 0) / len(grad_and_vars)\n",
    "            # deduplicate across indices\n",
    "            av, ai = _deduplicate_indexed_slices(avg_values, all_indices)\n",
    "            grad = tf.IndexedSlices(av, ai, dense_shape=g0.dense_shape)\n",
    "\n",
    "        else:\n",
    "            # a normal tensor can just do a simple average\n",
    "            grads = []\n",
    "            for g, v in grad_and_vars:\n",
    "                # Add 0 dimension to the gradients to represent the tower.\n",
    "                expanded_g = tf.expand_dims(g, 0)\n",
    "                # Append on a 'tower' dimension which we will average over \n",
    "                grads.append(expanded_g)\n",
    "\n",
    "            # Average over the 'tower' dimension.\n",
    "            grad = tf.concat(grads, 0)\n",
    "            grad = tf.reduce_mean(grad, 0)\n",
    "\n",
    "        # the Variables are redundant because they are shared\n",
    "        # across towers. So.. just return the first tower's pointer to\n",
    "        # the Variable.\n",
    "        v = grad_and_vars[0][1]\n",
    "        grad_and_var = (grad, v)\n",
    "\n",
    "        average_grads.append(grad_and_var)\n",
    "\n",
    "    assert len(average_grads) == len(list(zip(*tower_grads)))\n",
    "    \n",
    "    return average_grads\n",
    "\n",
    "\n",
    "def summary_gradient_updates(grads, opt, lr):\n",
    "    '''get summary ops for the magnitude of gradient updates'''\n",
    "\n",
    "    # strategy:\n",
    "    # make a dict of variable name -> [variable, grad, adagrad slot]\n",
    "    vars_grads = {}\n",
    "    for v in tf.trainable_variables():\n",
    "        vars_grads[v.name] = [v, None, None]\n",
    "    for g, v in grads:\n",
    "        vars_grads[v.name][1] = g\n",
    "        vars_grads[v.name][2] = opt.get_slot(v, 'accumulator')\n",
    "\n",
    "    # now make summaries\n",
    "    ret = []\n",
    "    for vname, (v, g, a) in vars_grads.items():\n",
    "\n",
    "        if g is None:\n",
    "            continue\n",
    "\n",
    "        if isinstance(g, tf.IndexedSlices):\n",
    "            # a sparse gradient - only take norm of params that are updated\n",
    "            values = tf.gather(v, g.indices)\n",
    "            updates = lr * g.values\n",
    "            if a is not None:\n",
    "                updates /= tf.sqrt(tf.gather(a, g.indices))\n",
    "        else:\n",
    "            values = v\n",
    "            updates = lr * g\n",
    "            if a is not None:\n",
    "                updates /= tf.sqrt(a)\n",
    "\n",
    "        values_norm = tf.sqrt(tf.reduce_sum(v * v)) + 1.0e-7\n",
    "        updates_norm = tf.sqrt(tf.reduce_sum(updates * updates))\n",
    "        ret.append(\n",
    "                tf.summary.scalar('UPDATE/' + vname.replace(\":\", \"_\"), updates_norm / values_norm))\n",
    "\n",
    "    return ret\n",
    "\n",
    "def _deduplicate_indexed_slices(values, indices):\n",
    "    \"\"\"Sums `values` associated with any non-unique `indices`.\n",
    "    Args:\n",
    "      values: A `Tensor` with rank >= 1.\n",
    "      indices: A one-dimensional integer `Tensor`, indexing into the first\n",
    "      dimension of `values` (as in an IndexedSlices object).\n",
    "    Returns:\n",
    "      A tuple of (`summed_values`, `unique_indices`) where `unique_indices` is a\n",
    "      de-duplicated version of `indices` and `summed_values` contains the sum of\n",
    "      `values` slices associated with each unique index.\n",
    "    \"\"\"\n",
    "    unique_indices, new_index_positions = tf.unique(indices)\n",
    "    summed_values = tf.unsorted_segment_sum(\n",
    "      values, new_index_positions,\n",
    "      tf.shape(unique_indices)[0])\n",
    "    return (summed_values, unique_indices)\n",
    "\n",
    "\n",
    "def _get_feed_dict_from_X(X, start, end, model, char_inputs, bidirectional):\n",
    "    feed_dict = {}\n",
    "    if not char_inputs:\n",
    "        token_ids = X['token_ids'][start:end]\n",
    "        feed_dict[model.token_ids] = token_ids\n",
    "    else:\n",
    "        # character inputs\n",
    "        char_ids = X['tokens_characters'][start:end]\n",
    "        feed_dict[model.tokens_characters] = char_ids\n",
    "\n",
    "    if bidirectional:\n",
    "        if not char_inputs:\n",
    "            feed_dict[model.token_ids_reverse] = \\\n",
    "                X['token_ids_reverse'][start:end]\n",
    "        else:\n",
    "            feed_dict[model.tokens_characters_reverse] = \\\n",
    "                X['tokens_characters_reverse'][start:end]\n",
    "\n",
    "    # now the targets with weights\n",
    "    next_id_placeholders = [[model.next_token_id, '']]\n",
    "    if bidirectional:\n",
    "        next_id_placeholders.append([model.next_token_id_reverse, '_reverse'])\n",
    "\n",
    "    for id_placeholder, suffix in next_id_placeholders:\n",
    "        name = 'next_token_id' + suffix\n",
    "        feed_dict[id_placeholder] = X[name][start:end]\n",
    "\n",
    "    return feed_dict\n",
    "\n",
    "\n",
    "def clip_by_global_norm_summary(t_list, clip_norm, norm_name, variables):\n",
    "    # wrapper around tf.clip_by_global_norm that also does summary ops of norms\n",
    "\n",
    "    # compute norms\n",
    "    # use global_norm with one element to handle IndexedSlices vs dense\n",
    "    norms = [tf.global_norm([t]) for t in t_list]\n",
    "\n",
    "    # summary ops before clipping\n",
    "    summary_ops = []\n",
    "    for ns, v in zip(norms, variables):\n",
    "        name = 'norm_pre_clip/' + v.name.replace(\":\", \"_\")\n",
    "        summary_ops.append(tf.summary.scalar(name, ns))\n",
    "\n",
    "    # clip \n",
    "    clipped_t_list, tf_norm = tf.clip_by_global_norm(t_list, clip_norm)\n",
    "\n",
    "    # summary ops after clipping\n",
    "    norms_post = [tf.global_norm([t]) for t in clipped_t_list]\n",
    "    for ns, v in zip(norms_post, variables):\n",
    "        name = 'norm_post_clip/' + v.name.replace(\":\", \"_\")\n",
    "        summary_ops.append(tf.summary.scalar(name, ns))\n",
    "\n",
    "    summary_ops.append(tf.summary.scalar(norm_name, tf_norm))\n",
    "\n",
    "    return clipped_t_list, tf_norm, summary_ops\n",
    "\n",
    "\n",
    "def clip_grads(grads, options, do_summaries, global_step):\n",
    "    # grads = [(grad1, var1), (grad2, var2), ...]\n",
    "    def _clip_norms(grad_and_vars, val, name):\n",
    "        # grad_and_vars is a list of (g, v) pairs\n",
    "        grad_tensors = [g for g, v in grad_and_vars]\n",
    "        vv = [v for g, v in grad_and_vars]\n",
    "        scaled_val = val\n",
    "        if do_summaries:\n",
    "            clipped_tensors, g_norm, so = clip_by_global_norm_summary(\n",
    "                grad_tensors, scaled_val, name, vv)\n",
    "        else:\n",
    "            so = []\n",
    "            clipped_tensors, g_norm = tf.clip_by_global_norm(\n",
    "                grad_tensors, scaled_val)\n",
    "\n",
    "        ret = []\n",
    "        for t, (g, v) in zip(clipped_tensors, grad_and_vars):\n",
    "            ret.append((t, v))\n",
    "\n",
    "        return ret, so\n",
    "\n",
    "    all_clip_norm_val = options['all_clip_norm_val']\n",
    "    ret, summary_ops = _clip_norms(grads, all_clip_norm_val, 'norm_grad')\n",
    "\n",
    "    assert len(ret) == len(grads)\n",
    "\n",
    "    return ret, summary_ops\n",
    "\n",
    "def train(options, data, n_gpus, tf_save_dir, tf_log_dir,\n",
    "          restart_ckpt_file=None):\n",
    "\n",
    "    # not restarting so save the options\n",
    "    if restart_ckpt_file is None:\n",
    "        with open(os.path.join(tf_save_dir, 'options.json'), 'w') as fout:\n",
    "            fout.write(json.dumps(options))\n",
    "\n",
    "    with tf.device('/cpu:0'):\n",
    "        global_step = tf.get_variable(\n",
    "            'global_step', [],\n",
    "            initializer=tf.constant_initializer(0), trainable=False)\n",
    "\n",
    "        # set up the optimizer\n",
    "        lr = options.get('learning_rate', 0.2)\n",
    "        opt = tf.train.AdagradOptimizer(learning_rate=lr,\n",
    "                                        initial_accumulator_value=1.0)\n",
    "\n",
    "        # calculate the gradients on each GPU\n",
    "        tower_grads = []\n",
    "        models = []\n",
    "        train_perplexity = tf.get_variable(\n",
    "            'train_perplexity', [],\n",
    "            initializer=tf.constant_initializer(0.0), trainable=False)\n",
    "        norm_summaries = []\n",
    "        for k in range(n_gpus):\n",
    "            #with tf.device('/gpu:%d' % k):\n",
    "            with tf.device('/cpu:%d'%k):\n",
    "                with tf.variable_scope('lm', reuse=k > 0):\n",
    "                    # calculate the loss for one model replica and get\n",
    "                    #   lstm states\n",
    "                    model = LanguageModel(options, True)\n",
    "                    loss = model.total_loss\n",
    "                    models.append(model)\n",
    "                    # get gradients\n",
    "                    grads = opt.compute_gradients(\n",
    "                        loss * options['unroll_steps'],\n",
    "                        aggregation_method=tf.AggregationMethod.EXPERIMENTAL_TREE,\n",
    "                    )\n",
    "                    tower_grads.append(grads)\n",
    "                    # keep track of loss across all GPUs\n",
    "                    train_perplexity += loss\n",
    "\n",
    "        print_variable_summary()\n",
    "\n",
    "        # calculate the mean of each gradient across all GPUs\n",
    "        grads = average_gradients(tower_grads, options['batch_size'], options)\n",
    "        grads, norm_summary_ops = clip_grads(grads, options, True, global_step)\n",
    "        norm_summaries.extend(norm_summary_ops)\n",
    "\n",
    "        # log the training perplexity\n",
    "        train_perplexity = tf.exp(train_perplexity / n_gpus)\n",
    "        perplexity_summmary = tf.summary.scalar(\n",
    "            'train_perplexity', train_perplexity)\n",
    "\n",
    "        # some histogram summaries.  all models use the same parameters\n",
    "        # so only need to summarize one\n",
    "        histogram_summaries = [\n",
    "            tf.summary.histogram('token_embedding', models[0].embedding)\n",
    "        ]\n",
    "        # tensors of the output from the LSTM layer\n",
    "        lstm_out = tf.get_collection('lstm_output_embeddings')\n",
    "        histogram_summaries.append(\n",
    "                tf.summary.histogram('lstm_embedding_0', lstm_out[0]))\n",
    "        if options.get('bidirectional', False):\n",
    "            # also have the backward embedding\n",
    "            histogram_summaries.append(\n",
    "                tf.summary.histogram('lstm_embedding_1', lstm_out[1]))\n",
    "\n",
    "        # apply the gradients to create the training operation\n",
    "        train_op = opt.apply_gradients(grads, global_step=global_step)\n",
    "\n",
    "        # histograms of variables\n",
    "        for v in tf.global_variables():\n",
    "            histogram_summaries.append(tf.summary.histogram(v.name.replace(\":\", \"_\"), v))\n",
    "\n",
    "        # get the gradient updates -- these aren't histograms, but we'll\n",
    "        # only update them when histograms are computed\n",
    "        histogram_summaries.extend(\n",
    "            summary_gradient_updates(grads, opt, lr))\n",
    "\n",
    "        saver = tf.train.Saver(tf.global_variables(), max_to_keep=2)\n",
    "        summary_op = tf.summary.merge(\n",
    "            [perplexity_summmary] + norm_summaries\n",
    "        )\n",
    "        hist_summary_op = tf.summary.merge(histogram_summaries)\n",
    "\n",
    "        init = tf.initialize_all_variables()\n",
    "\n",
    "    # do the training loop\n",
    "    bidirectional = options.get('bidirectional', False)\n",
    "    with tf.Session(config=tf.ConfigProto(\n",
    "            allow_soft_placement=True)) as sess:\n",
    "        sess.run(init)\n",
    "\n",
    "        # load the checkpoint data if needed\n",
    "        if restart_ckpt_file is not None:\n",
    "            loader = tf.train.Saver()\n",
    "            loader.restore(sess, restart_ckpt_file)\n",
    "            \n",
    "        summary_writer = tf.summary.FileWriter(tf_log_dir, sess.graph)\n",
    "\n",
    "        # For each batch:\n",
    "        # Get a batch of data from the generator. The generator will\n",
    "        # yield batches of size batch_size * n_gpus that are sliced\n",
    "        # and fed for each required placeholer.\n",
    "        #\n",
    "        # We also need to be careful with the LSTM states.  We will\n",
    "        # collect the final LSTM states after each batch, then feed\n",
    "        # them back in as the initial state for the next batch\n",
    "\n",
    "        batch_size = options['batch_size']\n",
    "        unroll_steps = options['unroll_steps']\n",
    "        n_train_tokens = options.get('n_train_tokens', 768648884)\n",
    "        n_tokens_per_batch = batch_size * unroll_steps * n_gpus\n",
    "        n_batches_per_epoch = int(n_train_tokens / n_tokens_per_batch)\n",
    "        n_batches_total = options['n_epochs'] * n_batches_per_epoch\n",
    "        print(\"Training for %s epochs and %s batches\" % (\n",
    "            options['n_epochs'], n_batches_total))\n",
    "\n",
    "        # get the initial lstm states\n",
    "        init_state_tensors = []\n",
    "        final_state_tensors = []\n",
    "        for model in models:\n",
    "            init_state_tensors.extend(model.init_lstm_state)\n",
    "            final_state_tensors.extend(model.final_lstm_state)\n",
    "\n",
    "        char_inputs = 'char_cnn' in options\n",
    "        if char_inputs:\n",
    "            max_chars = options['char_cnn']['max_characters_per_token']\n",
    "\n",
    "        if not char_inputs:\n",
    "            feed_dict = {\n",
    "                model.token_ids:\n",
    "                    np.zeros([batch_size, unroll_steps], dtype=np.int64)\n",
    "                for model in models\n",
    "            }\n",
    "        else:\n",
    "            feed_dict = {\n",
    "                model.tokens_characters:\n",
    "                    np.zeros([batch_size, unroll_steps, max_chars],\n",
    "                             dtype=np.int32)\n",
    "                for model in models\n",
    "            }\n",
    "\n",
    "        if bidirectional:\n",
    "            if not char_inputs:\n",
    "                feed_dict.update({\n",
    "                    model.token_ids_reverse:\n",
    "                        np.zeros([batch_size, unroll_steps], dtype=np.int64)\n",
    "                    for model in models\n",
    "                })\n",
    "            else:\n",
    "                feed_dict.update({\n",
    "                    model.tokens_characters_reverse:\n",
    "                        np.zeros([batch_size, unroll_steps, max_chars],\n",
    "                                 dtype=np.int32)\n",
    "                    for model in models\n",
    "                })\n",
    "\n",
    "        init_state_values = sess.run(init_state_tensors, feed_dict=feed_dict)\n",
    "\n",
    "        t1 = time.time()\n",
    "        data_gen = data.iter_batches(batch_size * n_gpus, unroll_steps)\n",
    "        for batch_no, batch in enumerate(data_gen, start=1):\n",
    "\n",
    "            # slice the input in the batch for the feed_dict\n",
    "            X = batch\n",
    "            feed_dict = {t: v for t, v in zip(\n",
    "                                        init_state_tensors, init_state_values)}\n",
    "            for k in range(n_gpus):\n",
    "                model = models[k]\n",
    "                start = k * batch_size\n",
    "                end = (k + 1) * batch_size\n",
    "\n",
    "                feed_dict.update(\n",
    "                    _get_feed_dict_from_X(X, start, end, model,\n",
    "                                          char_inputs, bidirectional)\n",
    "                )\n",
    "\n",
    "            # This runs the train_op, summaries and the \"final_state_tensors\"\n",
    "            #   which just returns the tensors, passing in the initial\n",
    "            #   state tensors, token ids and next token ids\n",
    "            if batch_no % 1250 != 0:\n",
    "                ret = sess.run(\n",
    "                    [train_op, summary_op, train_perplexity] +\n",
    "                                                final_state_tensors,\n",
    "                    feed_dict=feed_dict\n",
    "                )\n",
    "\n",
    "                # first three entries of ret are:\n",
    "                #  train_op, summary_op, train_perplexity\n",
    "                # last entries are the final states -- set them to\n",
    "                # init_state_values\n",
    "                # for next batch\n",
    "                init_state_values = ret[3:]\n",
    "\n",
    "            else:\n",
    "                # also run the histogram summaries\n",
    "                ret = sess.run(\n",
    "                    [train_op, summary_op, train_perplexity, hist_summary_op] + \n",
    "                                                final_state_tensors,\n",
    "                    feed_dict=feed_dict\n",
    "                )\n",
    "                init_state_values = ret[4:]\n",
    "                \n",
    "\n",
    "            if batch_no % 1250 == 0:\n",
    "                summary_writer.add_summary(ret[3], batch_no)\n",
    "            if batch_no % 50 == 0:\n",
    "                # write the summaries to tensorboard and display perplexity\n",
    "                summary_writer.add_summary(ret[1], batch_no)\n",
    "                print(\"Batch %s, train_perplexity=%s\" % (batch_no, ret[2]))\n",
    "                print(\"Total time: %s\" % (time.time() - t1))\n",
    "\n",
    "            if (batch_no % 1250 == 0) or (batch_no == n_batches_total):\n",
    "                # save the model\n",
    "                checkpoint_path = os.path.join(tf_save_dir, 'model.ckpt')\n",
    "                saver.save(sess, checkpoint_path, global_step=global_step)\n",
    "\n",
    "            if batch_no == n_batches_total:\n",
    "                # done training!\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# begin to training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 shards at ./data/dataset/corpus.txt\n",
      "Loading data from: ./data/dataset/corpus.txt\n",
      "Loaded 10662 sentences.\n",
      "Finished loading\n",
      "Found 1 shards at ./data/dataset/corpus.txt\n",
      "Loading data from: ./data/dataset/corpus.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0725 21:31:54.512269 4558599616 deprecation.py:506] From /Users/jozee/miniconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py:180: calling squeeze (from tensorflow.python.ops.array_ops) with squeeze_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the `axis` argument instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10662 sentences.\n",
      "Finished loading\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0725 21:31:54.773779 4558599616 deprecation.py:323] From <ipython-input-14-ae9a688aeb2f>:349: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "W0725 21:31:54.783967 4558599616 deprecation.py:323] From <ipython-input-14-ae9a688aeb2f>:373: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "W0725 21:31:54.840346 4558599616 deprecation.py:323] From <ipython-input-14-ae9a688aeb2f>:387: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USING SKIP CONNECTIONS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0725 21:31:55.162467 4558599616 deprecation.py:506] From /Users/jozee/miniconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0725 21:31:55.176028 4558599616 deprecation.py:506] From /Users/jozee/miniconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py:961: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0725 21:31:57.413887 4558599616 deprecation.py:506] From <ipython-input-14-ae9a688aeb2f>:401: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0725 21:31:59.998725 4558599616 deprecation.py:323] From /Users/jozee/miniconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0725 21:32:10.211089 4558599616 variables.py:2429] Variable += will be deprecated. Use variable.assign_add if you want assignment to the variable value or 'x = x + y' if you want a new python Tensor object.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['global_step:0', TensorShape([])],\n",
      " ['lm/CNN/W_cnn_0:0',\n",
      "  TensorShape([Dimension(1), Dimension(1), Dimension(16), Dimension(32)])],\n",
      " ['lm/CNN/W_cnn_1:0',\n",
      "  TensorShape([Dimension(1), Dimension(2), Dimension(16), Dimension(32)])],\n",
      " ['lm/CNN/W_cnn_2:0',\n",
      "  TensorShape([Dimension(1), Dimension(3), Dimension(16), Dimension(64)])],\n",
      " ['lm/CNN/W_cnn_3:0',\n",
      "  TensorShape([Dimension(1), Dimension(4), Dimension(16), Dimension(128)])],\n",
      " ['lm/CNN/W_cnn_4:0',\n",
      "  TensorShape([Dimension(1), Dimension(5), Dimension(16), Dimension(256)])],\n",
      " ['lm/CNN/W_cnn_5:0',\n",
      "  TensorShape([Dimension(1), Dimension(6), Dimension(16), Dimension(512)])],\n",
      " ['lm/CNN/W_cnn_6:0',\n",
      "  TensorShape([Dimension(1), Dimension(7), Dimension(16), Dimension(1024)])],\n",
      " ['lm/CNN/b_cnn_0:0', TensorShape([Dimension(32)])],\n",
      " ['lm/CNN/b_cnn_1:0', TensorShape([Dimension(32)])],\n",
      " ['lm/CNN/b_cnn_2:0', TensorShape([Dimension(64)])],\n",
      " ['lm/CNN/b_cnn_3:0', TensorShape([Dimension(128)])],\n",
      " ['lm/CNN/b_cnn_4:0', TensorShape([Dimension(256)])],\n",
      " ['lm/CNN/b_cnn_5:0', TensorShape([Dimension(512)])],\n",
      " ['lm/CNN/b_cnn_6:0', TensorShape([Dimension(1024)])],\n",
      " ['lm/CNN_high_0/W_carry:0', TensorShape([Dimension(2048), Dimension(2048)])],\n",
      " ['lm/CNN_high_0/W_transform:0',\n",
      "  TensorShape([Dimension(2048), Dimension(2048)])],\n",
      " ['lm/CNN_high_0/b_carry:0', TensorShape([Dimension(2048)])],\n",
      " ['lm/CNN_high_0/b_transform:0', TensorShape([Dimension(2048)])],\n",
      " ['lm/CNN_high_1/W_carry:0', TensorShape([Dimension(2048), Dimension(2048)])],\n",
      " ['lm/CNN_high_1/W_transform:0',\n",
      "  TensorShape([Dimension(2048), Dimension(2048)])],\n",
      " ['lm/CNN_high_1/b_carry:0', TensorShape([Dimension(2048)])],\n",
      " ['lm/CNN_high_1/b_transform:0', TensorShape([Dimension(2048)])],\n",
      " ['lm/CNN_proj/W_proj:0', TensorShape([Dimension(2048), Dimension(512)])],\n",
      " ['lm/CNN_proj/b_proj:0', TensorShape([Dimension(512)])],\n",
      " ['lm/RNN_0/rnn/multi_rnn_cell/cell_0/lstm_cell/bias:0',\n",
      "  TensorShape([Dimension(16384)])],\n",
      " ['lm/RNN_0/rnn/multi_rnn_cell/cell_0/lstm_cell/kernel:0',\n",
      "  TensorShape([Dimension(1024), Dimension(16384)])],\n",
      " ['lm/RNN_0/rnn/multi_rnn_cell/cell_0/lstm_cell/projection/kernel:0',\n",
      "  TensorShape([Dimension(4096), Dimension(512)])],\n",
      " ['lm/RNN_0/rnn/multi_rnn_cell/cell_1/lstm_cell/bias:0',\n",
      "  TensorShape([Dimension(16384)])],\n",
      " ['lm/RNN_0/rnn/multi_rnn_cell/cell_1/lstm_cell/kernel:0',\n",
      "  TensorShape([Dimension(1024), Dimension(16384)])],\n",
      " ['lm/RNN_0/rnn/multi_rnn_cell/cell_1/lstm_cell/projection/kernel:0',\n",
      "  TensorShape([Dimension(4096), Dimension(512)])],\n",
      " ['lm/RNN_1/rnn/multi_rnn_cell/cell_0/lstm_cell/bias:0',\n",
      "  TensorShape([Dimension(16384)])],\n",
      " ['lm/RNN_1/rnn/multi_rnn_cell/cell_0/lstm_cell/kernel:0',\n",
      "  TensorShape([Dimension(1024), Dimension(16384)])],\n",
      " ['lm/RNN_1/rnn/multi_rnn_cell/cell_0/lstm_cell/projection/kernel:0',\n",
      "  TensorShape([Dimension(4096), Dimension(512)])],\n",
      " ['lm/RNN_1/rnn/multi_rnn_cell/cell_1/lstm_cell/bias:0',\n",
      "  TensorShape([Dimension(16384)])],\n",
      " ['lm/RNN_1/rnn/multi_rnn_cell/cell_1/lstm_cell/kernel:0',\n",
      "  TensorShape([Dimension(1024), Dimension(16384)])],\n",
      " ['lm/RNN_1/rnn/multi_rnn_cell/cell_1/lstm_cell/projection/kernel:0',\n",
      "  TensorShape([Dimension(4096), Dimension(512)])],\n",
      " ['lm/char_embed:0', TensorShape([Dimension(261), Dimension(16)])],\n",
      " ['lm/softmax/W:0', TensorShape([Dimension(20335), Dimension(512)])],\n",
      " ['lm/softmax/b:0', TensorShape([Dimension(20335)])],\n",
      " ['train_perplexity:0', TensorShape([])]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0725 21:32:10.992384 4558599616 deprecation.py:506] From /Users/jozee/miniconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/training/adagrad.py:76: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0725 21:32:11.844080 4558599616 deprecation.py:323] From /Users/jozee/miniconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:193: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "W0725 21:32:19.379009 4558599616 meta_graph.py:449] Issue encountered when serializing lstm_output_embeddings.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'list' object has no attribute 'name'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 2 epochs and 88 batches\n",
      "Loading data from: ./data/dataset/corpus.txt\n",
      "Loaded 10662 sentences.\n",
      "Finished loading\n",
      "Loading data from: ./data/dataset/corpus.txt\n",
      "Loaded 10662 sentences.\n",
      "Finished loading\n",
      "Batch 50, train_perplexity=6257.8887\n",
      "Total time: 3307.9138181209564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0725 23:11:59.001498 4558599616 meta_graph.py:449] Issue encountered when serializing lstm_output_embeddings.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'list' object has no attribute 'name'\n"
     ]
    }
   ],
   "source": [
    "vocab = load_vocab(cur_dir+\"/dataset/vocab.txt\", 50)\n",
    "batch_size = 128  # batch size for each GPU\n",
    "n_gpus = 1\n",
    "n_train_tokens = len(split)\n",
    "options = {\n",
    "     'bidirectional': True,\n",
    "\n",
    "     'char_cnn': {'activation': 'relu',\n",
    "      'embedding': {'dim': 16},\n",
    "      'filters': [[1, 32],\n",
    "       [2, 32],\n",
    "       [3, 64],\n",
    "       [4, 128],\n",
    "       [5, 256],\n",
    "       [6, 512],\n",
    "       [7, 1024]],\n",
    "      'max_characters_per_token': 50,\n",
    "      'n_characters': 261,\n",
    "      'n_highway': 2},\n",
    "    \n",
    "     'dropout': 0.1,\n",
    "    \n",
    "     'lstm': {\n",
    "      'cell_clip': 3,\n",
    "      'dim': 4096,\n",
    "      'n_layers': 2,\n",
    "      'proj_clip': 3,\n",
    "      'projection_dim': 512,\n",
    "      'use_skip_connections': True},\n",
    "    \n",
    "     'all_clip_norm_val': 10.0,\n",
    "    \n",
    "     'n_epochs': 2,\n",
    "     'n_train_tokens': n_train_tokens,\n",
    "     'batch_size': batch_size,\n",
    "     'n_tokens_vocab': vocab.size,\n",
    "     'unroll_steps': 20,\n",
    "     'n_negative_samples_batch': 8192,\n",
    "}\n",
    "\n",
    "prefix = cur_dir+\"/dataset/corpus.txt\"\n",
    "data = BidirectionalLMDataset(prefix, vocab, test=False,shuffle_on_load=True)\n",
    "tf_save_dir = cur_dir+\"/model\"\n",
    "tf_log_dir = cur_dir+\"/model\"\n",
    "\n",
    "#开始训练\n",
    "train(options, data, n_gpus, tf_save_dir, tf_log_dir)\n",
    "#dump options to options.json for next step\n",
    "with open(os.path.join(cur_dir+'/model', 'options.json'), 'w') as fout:\n",
    "    fout.write(json.dumps(options))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert the tensorflow checkpoint to hdf5 for prediction\n",
    "\n",
    "1. run dump_weights  小节\n",
    "2. LanguageModel 小节"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0725 23:27:23.909978 4500207040 deprecation.py:506] From /Users/jozee/miniconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py:180: calling squeeze (from tensorflow.python.ops.array_ops) with squeeze_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the `axis` argument instead\n",
      "W0725 23:27:24.168454 4500207040 deprecation.py:323] From <ipython-input-4-ae9a688aeb2f>:349: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "W0725 23:27:24.171930 4500207040 deprecation.py:323] From <ipython-input-4-ae9a688aeb2f>:373: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "W0725 23:27:24.221465 4500207040 deprecation.py:323] From <ipython-input-4-ae9a688aeb2f>:387: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USING SKIP CONNECTIONS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0725 23:27:24.560481 4500207040 deprecation.py:506] From /Users/jozee/miniconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0725 23:27:24.577875 4500207040 deprecation.py:506] From /Users/jozee/miniconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py:961: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0725 23:27:28.476819 4500207040 deprecation.py:323] From /Users/jozee/miniconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "I0725 23:27:28.479129 4500207040 saver.py:1280] Restoring parameters from ./data/model/model.ckpt-88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving variable lm/char_embed:0 with name char_embed\n",
      "Saving variable lm/CNN/W_cnn_0:0 with name CNN/W_cnn_0\n",
      "Saving variable lm/CNN/b_cnn_0:0 with name CNN/b_cnn_0\n",
      "Saving variable lm/CNN/W_cnn_1:0 with name CNN/W_cnn_1\n",
      "Saving variable lm/CNN/b_cnn_1:0 with name CNN/b_cnn_1\n",
      "Saving variable lm/CNN/W_cnn_2:0 with name CNN/W_cnn_2\n",
      "Saving variable lm/CNN/b_cnn_2:0 with name CNN/b_cnn_2\n",
      "Saving variable lm/CNN/W_cnn_3:0 with name CNN/W_cnn_3\n",
      "Saving variable lm/CNN/b_cnn_3:0 with name CNN/b_cnn_3\n",
      "Saving variable lm/CNN/W_cnn_4:0 with name CNN/W_cnn_4\n",
      "Saving variable lm/CNN/b_cnn_4:0 with name CNN/b_cnn_4\n",
      "Saving variable lm/CNN/W_cnn_5:0 with name CNN/W_cnn_5\n",
      "Saving variable lm/CNN/b_cnn_5:0 with name CNN/b_cnn_5\n",
      "Saving variable lm/CNN/W_cnn_6:0 with name CNN/W_cnn_6\n",
      "Saving variable lm/CNN/b_cnn_6:0 with name CNN/b_cnn_6\n",
      "Saving variable lm/CNN_proj/W_proj:0 with name CNN_proj/W_proj\n",
      "Saving variable lm/CNN_proj/b_proj:0 with name CNN_proj/b_proj\n",
      "Saving variable lm/CNN_high_0/W_carry:0 with name CNN_high_0/W_carry\n",
      "Saving variable lm/CNN_high_0/b_carry:0 with name CNN_high_0/b_carry\n",
      "Saving variable lm/CNN_high_0/W_transform:0 with name CNN_high_0/W_transform\n",
      "Saving variable lm/CNN_high_0/b_transform:0 with name CNN_high_0/b_transform\n",
      "Saving variable lm/CNN_high_1/W_carry:0 with name CNN_high_1/W_carry\n",
      "Saving variable lm/CNN_high_1/b_carry:0 with name CNN_high_1/b_carry\n",
      "Saving variable lm/CNN_high_1/W_transform:0 with name CNN_high_1/W_transform\n",
      "Saving variable lm/CNN_high_1/b_transform:0 with name CNN_high_1/b_transform\n",
      "Saving variable lm/RNN_0/rnn/multi_rnn_cell/cell_0/lstm_cell/kernel:0 with name RNN_0/RNN/MultiRNNCell/Cell0/LSTMCell/W_0\n",
      "Saving variable lm/RNN_0/rnn/multi_rnn_cell/cell_0/lstm_cell/bias:0 with name RNN_0/RNN/MultiRNNCell/Cell0/LSTMCell/B\n",
      "Saving variable lm/RNN_0/rnn/multi_rnn_cell/cell_0/lstm_cell/projection/kernel:0 with name RNN_0/RNN/MultiRNNCell/Cell0/LSTMCell/W_P_0\n",
      "Saving variable lm/RNN_0/rnn/multi_rnn_cell/cell_1/lstm_cell/kernel:0 with name RNN_0/RNN/MultiRNNCell/Cell1/LSTMCell/W_0\n",
      "Saving variable lm/RNN_0/rnn/multi_rnn_cell/cell_1/lstm_cell/bias:0 with name RNN_0/RNN/MultiRNNCell/Cell1/LSTMCell/B\n",
      "Saving variable lm/RNN_0/rnn/multi_rnn_cell/cell_1/lstm_cell/projection/kernel:0 with name RNN_0/RNN/MultiRNNCell/Cell1/LSTMCell/W_P_0\n",
      "Saving variable lm/RNN_1/rnn/multi_rnn_cell/cell_0/lstm_cell/kernel:0 with name RNN_1/RNN/MultiRNNCell/Cell0/LSTMCell/W_0\n",
      "Saving variable lm/RNN_1/rnn/multi_rnn_cell/cell_0/lstm_cell/bias:0 with name RNN_1/RNN/MultiRNNCell/Cell0/LSTMCell/B\n",
      "Saving variable lm/RNN_1/rnn/multi_rnn_cell/cell_0/lstm_cell/projection/kernel:0 with name RNN_1/RNN/MultiRNNCell/Cell0/LSTMCell/W_P_0\n",
      "Saving variable lm/RNN_1/rnn/multi_rnn_cell/cell_1/lstm_cell/kernel:0 with name RNN_1/RNN/MultiRNNCell/Cell1/LSTMCell/W_0\n",
      "Saving variable lm/RNN_1/rnn/multi_rnn_cell/cell_1/lstm_cell/bias:0 with name RNN_1/RNN/MultiRNNCell/Cell1/LSTMCell/B\n",
      "Saving variable lm/RNN_1/rnn/multi_rnn_cell/cell_1/lstm_cell/projection/kernel:0 with name RNN_1/RNN/MultiRNNCell/Cell1/LSTMCell/W_P_0\n"
     ]
    }
   ],
   "source": [
    "dump_weights(cur_dir+'/model',cur_dir+'/model/weights.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 将语料转化成ELMo embedding\n",
    "\n",
    "参考：usage_token.py\n",
    "\n",
    "-  tokenbatcher function\n",
    "- Batcher function\n",
    "- vocabulary class\n",
    "- UnicodeCharsVocabulary class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \\_pretrained\\_initializer function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pretrained_initializer(varname, weight_file, embedding_weight_file=None):\n",
    "    '''\n",
    "    We'll stub out all the initializers in the pretrained LM with\n",
    "    a function that loads the weights from the file\n",
    "    '''\n",
    "    weight_name_map = {}\n",
    "    for i in range(2):\n",
    "        for j in range(8):  # if we decide to add more layers\n",
    "            root = 'RNN_{}/RNN/MultiRNNCell/Cell{}'.format(i, j)\n",
    "            weight_name_map[root + '/rnn/lstm_cell/kernel'] = \\\n",
    "                root + '/LSTMCell/W_0'\n",
    "            weight_name_map[root + '/rnn/lstm_cell/bias'] = \\\n",
    "                root + '/LSTMCell/B'\n",
    "            weight_name_map[root + '/rnn/lstm_cell/projection/kernel'] = \\\n",
    "                root + '/LSTMCell/W_P_0'\n",
    "\n",
    "    # convert the graph name to that in the checkpoint\n",
    "    varname_in_file = varname[5:]\n",
    "    if varname_in_file.startswith('RNN'):\n",
    "        varname_in_file = weight_name_map[varname_in_file]\n",
    "\n",
    "    if varname_in_file == 'embedding':\n",
    "        with h5py.File(embedding_weight_file, 'r') as fin:\n",
    "            # Have added a special 0 index for padding not present\n",
    "            # in the original model.\n",
    "            embed_weights = fin[varname_in_file][...]\n",
    "            weights = np.zeros(\n",
    "                (embed_weights.shape[0] + 1, embed_weights.shape[1]),\n",
    "                dtype=DTYPE\n",
    "            )\n",
    "            weights[1:, :] = embed_weights\n",
    "    else:\n",
    "        with h5py.File(weight_file, 'r') as fin:\n",
    "            if varname_in_file == 'char_embed':\n",
    "                # Have added a special 0 index for padding not present\n",
    "                # in the original model.\n",
    "                char_embed_weights = fin[varname_in_file][...]\n",
    "                weights = np.zeros(\n",
    "                    (char_embed_weights.shape[0] + 1,\n",
    "                     char_embed_weights.shape[1]),\n",
    "                    dtype=DTYPE\n",
    "                )\n",
    "                weights[1:, :] = char_embed_weights\n",
    "            else:\n",
    "                weights = fin[varname_in_file][...]\n",
    "\n",
    "    # Tensorflow initializers are callables that accept a shape parameter\n",
    "    # and some optional kwargs\n",
    "    def ret(shape, **kwargs):\n",
    "        if list(shape) != list(weights.shape):\n",
    "            raise ValueError(\n",
    "                \"Invalid shape initializing {0}, got {1}, expected {2}\".format(\n",
    "                    varname_in_file, shape, weights.shape)\n",
    "            )\n",
    "        return weights\n",
    "\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BidirectionalLanguageModel Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BidirectionalLanguageModel(object):\n",
    "    def __init__(\n",
    "            self,\n",
    "            options_file: str,\n",
    "            weight_file: str,\n",
    "            use_character_inputs=True,\n",
    "            embedding_weight_file=None,\n",
    "            max_batch_size=128,\n",
    "        ):\n",
    "        '''\n",
    "        Creates the language model computational graph and loads weights\n",
    "        Two options for input type:\n",
    "            (1) To use character inputs (paired with Batcher)\n",
    "                pass use_character_inputs=True, and ids_placeholder\n",
    "                of shape (None, None, max_characters_per_token)\n",
    "                to __call__\n",
    "            (2) To use token ids as input (paired with TokenBatcher),\n",
    "                pass use_character_inputs=False and ids_placeholder\n",
    "                of shape (None, None) to __call__.\n",
    "                In this case, embedding_weight_file is also required input\n",
    "        options_file: location of the json formatted file with\n",
    "                      LM hyperparameters\n",
    "        weight_file: location of the hdf5 file with LM weights\n",
    "        use_character_inputs: if True, then use character ids as input,\n",
    "            otherwise use token ids\n",
    "        max_batch_size: the maximum allowable batch size \n",
    "        '''\n",
    "        with open(options_file, 'r') as fin:\n",
    "            options = json.load(fin)\n",
    "\n",
    "        if not use_character_inputs:\n",
    "            if embedding_weight_file is None:\n",
    "                raise ValueError(\n",
    "                    \"embedding_weight_file is required input with \"\n",
    "                    \"not use_character_inputs\"\n",
    "                )\n",
    "\n",
    "        self._options = options\n",
    "        self._weight_file = weight_file\n",
    "        self._embedding_weight_file = embedding_weight_file\n",
    "        self._use_character_inputs = use_character_inputs\n",
    "        self._max_batch_size = max_batch_size\n",
    "\n",
    "        self._ops = {}\n",
    "        self._graphs = {}\n",
    "\n",
    "    def __call__(self, ids_placeholder):\n",
    "        '''\n",
    "        Given the input character ids (or token ids), returns a dictionary\n",
    "            with tensorflow ops:\n",
    "            {'lm_embeddings': embedding_op,\n",
    "             'lengths': sequence_lengths_op,\n",
    "             'mask': op to compute mask}\n",
    "        embedding_op computes the LM embeddings and is shape\n",
    "            (None, 3, None, 1024)\n",
    "        lengths_op computes the sequence lengths and is shape (None, )\n",
    "        mask computes the sequence mask and is shape (None, None)\n",
    "        ids_placeholder: a tf.placeholder of type int32.\n",
    "            If use_character_inputs=True, it is shape\n",
    "                (None, None, max_characters_per_token) and holds the input\n",
    "                character ids for a batch\n",
    "            If use_character_input=False, it is shape (None, None) and\n",
    "                holds the input token ids for a batch\n",
    "        '''\n",
    "        if ids_placeholder in self._ops:\n",
    "            # have already created ops for this placeholder, just return them\n",
    "            ret = self._ops[ids_placeholder]\n",
    "\n",
    "        else:\n",
    "            # need to create the graph\n",
    "            if len(self._ops) == 0:\n",
    "                # first time creating the graph, don't reuse variables\n",
    "                lm_graph = BidirectionalLanguageModelGraph(\n",
    "                    self._options,\n",
    "                    self._weight_file,\n",
    "                    ids_placeholder,\n",
    "                    embedding_weight_file=self._embedding_weight_file,\n",
    "                    use_character_inputs=self._use_character_inputs,\n",
    "                    max_batch_size=self._max_batch_size)\n",
    "            else:\n",
    "                with tf.variable_scope('', reuse=True):\n",
    "                    lm_graph = BidirectionalLanguageModelGraph(\n",
    "                        self._options,\n",
    "                        self._weight_file,\n",
    "                        ids_placeholder,\n",
    "                        embedding_weight_file=self._embedding_weight_file,\n",
    "                        use_character_inputs=self._use_character_inputs,\n",
    "                        max_batch_size=self._max_batch_size)\n",
    "\n",
    "            ops = self._build_ops(lm_graph)\n",
    "            self._ops[ids_placeholder] = ops\n",
    "            self._graphs[ids_placeholder] = lm_graph\n",
    "            ret = ops\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def _build_ops(self, lm_graph):\n",
    "        with tf.control_dependencies([lm_graph.update_state_op]):\n",
    "            # get the LM embeddings\n",
    "            token_embeddings = lm_graph.embedding\n",
    "            layers = [\n",
    "                tf.concat([token_embeddings, token_embeddings], axis=2)\n",
    "            ]\n",
    "\n",
    "            n_lm_layers = len(lm_graph.lstm_outputs['forward'])\n",
    "            for i in range(n_lm_layers):\n",
    "                layers.append(\n",
    "                    tf.concat(\n",
    "                        [lm_graph.lstm_outputs['forward'][i],\n",
    "                         lm_graph.lstm_outputs['backward'][i]],\n",
    "                        axis=-1\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            # The layers include the BOS/EOS tokens.  Remove them\n",
    "            sequence_length_wo_bos_eos = lm_graph.sequence_lengths - 2\n",
    "            layers_without_bos_eos = []\n",
    "            for layer in layers:\n",
    "                layer_wo_bos_eos = layer[:, 1:, :]\n",
    "                layer_wo_bos_eos = tf.reverse_sequence(\n",
    "                    layer_wo_bos_eos, \n",
    "                    lm_graph.sequence_lengths - 1,\n",
    "                    seq_axis=1,\n",
    "                    batch_axis=0,\n",
    "                )\n",
    "                layer_wo_bos_eos = layer_wo_bos_eos[:, 1:, :]\n",
    "                layer_wo_bos_eos = tf.reverse_sequence(\n",
    "                    layer_wo_bos_eos,\n",
    "                    sequence_length_wo_bos_eos,\n",
    "                    seq_axis=1,\n",
    "                    batch_axis=0,\n",
    "                )\n",
    "                layers_without_bos_eos.append(layer_wo_bos_eos)\n",
    "\n",
    "            # concatenate the layers\n",
    "            lm_embeddings = tf.concat(\n",
    "                [tf.expand_dims(t, axis=1) for t in layers_without_bos_eos],\n",
    "                axis=1\n",
    "            )\n",
    "\n",
    "            # get the mask op without bos/eos.\n",
    "            # tf doesn't support reversing boolean tensors, so cast\n",
    "            # to int then back\n",
    "            mask_wo_bos_eos = tf.cast(lm_graph.mask[:, 1:], 'int32')\n",
    "            mask_wo_bos_eos = tf.reverse_sequence(\n",
    "                mask_wo_bos_eos,\n",
    "                lm_graph.sequence_lengths - 1,\n",
    "                seq_axis=1,\n",
    "                batch_axis=0,\n",
    "            )\n",
    "            mask_wo_bos_eos = mask_wo_bos_eos[:, 1:]\n",
    "            mask_wo_bos_eos = tf.reverse_sequence(\n",
    "                mask_wo_bos_eos,\n",
    "                sequence_length_wo_bos_eos,\n",
    "                seq_axis=1,\n",
    "                batch_axis=0,\n",
    "            )\n",
    "            mask_wo_bos_eos = tf.cast(mask_wo_bos_eos, 'bool')\n",
    "\n",
    "        return {\n",
    "            'lm_embeddings': lm_embeddings, \n",
    "            'lengths': sequence_length_wo_bos_eos,\n",
    "            'token_embeddings': lm_graph.embedding,\n",
    "            'mask': mask_wo_bos_eos,\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "class BidirectionalLanguageModelGraph(object):\n",
    "    '''\n",
    "    Creates the computational graph and holds the ops necessary for runnint\n",
    "    a bidirectional language model\n",
    "    '''\n",
    "    def __init__(self, options, weight_file, ids_placeholder,\n",
    "                 use_character_inputs=True, embedding_weight_file=None,\n",
    "                 max_batch_size=128):\n",
    "\n",
    "        self.options = options\n",
    "        self._max_batch_size = max_batch_size\n",
    "        self.ids_placeholder = ids_placeholder\n",
    "        self.use_character_inputs = use_character_inputs\n",
    "\n",
    "        # this custom_getter will make all variables not trainable and\n",
    "        # override the default initializer\n",
    "        def custom_getter(getter, name, *args, **kwargs):\n",
    "            kwargs['trainable'] = False\n",
    "            kwargs['initializer'] = _pretrained_initializer(\n",
    "                name, weight_file, embedding_weight_file\n",
    "            )\n",
    "            return getter(name, *args, **kwargs)\n",
    "\n",
    "        if embedding_weight_file is not None:\n",
    "            # get the vocab size\n",
    "            with h5py.File(embedding_weight_file, 'r') as fin:\n",
    "                # +1 for padding\n",
    "                self._n_tokens_vocab = fin['embedding'].shape[0] + 1\n",
    "        else:\n",
    "            self._n_tokens_vocab = None\n",
    "\n",
    "        with tf.variable_scope('bilm', custom_getter=custom_getter):\n",
    "            self._build()\n",
    "\n",
    "    def _build(self):\n",
    "        if self.use_character_inputs:\n",
    "            self._build_word_char_embeddings()\n",
    "        else:\n",
    "            self._build_word_embeddings()\n",
    "        self._build_lstms()\n",
    "\n",
    "    def _build_word_char_embeddings(self):\n",
    "        '''\n",
    "        options contains key 'char_cnn': {\n",
    "        'n_characters': 262,\n",
    "        # includes the start / end characters\n",
    "        'max_characters_per_token': 50,\n",
    "        'filters': [\n",
    "            [1, 32],\n",
    "            [2, 32],\n",
    "            [3, 64],\n",
    "            [4, 128],\n",
    "            [5, 256],\n",
    "            [6, 512],\n",
    "            [7, 512]\n",
    "        ],\n",
    "        'activation': 'tanh',\n",
    "        # for the character embedding\n",
    "        'embedding': {'dim': 16}\n",
    "        # for highway layers\n",
    "        # if omitted, then no highway layers\n",
    "        'n_highway': 2,\n",
    "        }\n",
    "        '''\n",
    "        projection_dim = self.options['lstm']['projection_dim']\n",
    "\n",
    "        cnn_options = self.options['char_cnn']\n",
    "        filters = cnn_options['filters']\n",
    "        n_filters = sum(f[1] for f in filters)\n",
    "        max_chars = cnn_options['max_characters_per_token']\n",
    "        char_embed_dim = cnn_options['embedding']['dim']\n",
    "        n_chars = cnn_options['n_characters']\n",
    "        if n_chars != 262:\n",
    "            raise InvalidNumberOfCharacters(\n",
    "                \"Set n_characters=262 after training see the README.md\"\n",
    "            )\n",
    "        if cnn_options['activation'] == 'tanh':\n",
    "            activation = tf.nn.tanh\n",
    "        elif cnn_options['activation'] == 'relu':\n",
    "            activation = tf.nn.relu\n",
    "\n",
    "        # the character embeddings\n",
    "        with tf.device(\"/cpu:0\"):\n",
    "            self.embedding_weights = tf.get_variable(\n",
    "                    \"char_embed\", [n_chars, char_embed_dim],\n",
    "                    dtype=DTYPE,\n",
    "                    initializer=tf.random_uniform_initializer(-1.0, 1.0)\n",
    "            )\n",
    "            # shape (batch_size, unroll_steps, max_chars, embed_dim)\n",
    "            self.char_embedding = tf.nn.embedding_lookup(self.embedding_weights,\n",
    "                                                    self.ids_placeholder)\n",
    "\n",
    "        # the convolutions\n",
    "        def make_convolutions(inp):\n",
    "            with tf.variable_scope('CNN') as scope:\n",
    "                convolutions = []\n",
    "                for i, (width, num) in enumerate(filters):\n",
    "                    if cnn_options['activation'] == 'relu':\n",
    "                        # He initialization for ReLU activation\n",
    "                        # with char embeddings init between -1 and 1\n",
    "                        #w_init = tf.random_normal_initializer(\n",
    "                        #    mean=0.0,\n",
    "                        #    stddev=np.sqrt(2.0 / (width * char_embed_dim))\n",
    "                        #)\n",
    "\n",
    "                        # Kim et al 2015, +/- 0.05\n",
    "                        w_init = tf.random_uniform_initializer(\n",
    "                            minval=-0.05, maxval=0.05)\n",
    "                    elif cnn_options['activation'] == 'tanh':\n",
    "                        # glorot init\n",
    "                        w_init = tf.random_normal_initializer(\n",
    "                            mean=0.0,\n",
    "                            stddev=np.sqrt(1.0 / (width * char_embed_dim))\n",
    "                        )\n",
    "                    w = tf.get_variable(\n",
    "                        \"W_cnn_%s\" % i,\n",
    "                        [1, width, char_embed_dim, num],\n",
    "                        initializer=w_init,\n",
    "                        dtype=DTYPE)\n",
    "                    b = tf.get_variable(\n",
    "                        \"b_cnn_%s\" % i, [num], dtype=DTYPE,\n",
    "                        initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "                    conv = tf.nn.conv2d(\n",
    "                            inp, w,\n",
    "                            strides=[1, 1, 1, 1],\n",
    "                            padding=\"VALID\") + b\n",
    "                    # now max pool\n",
    "                    conv = tf.nn.max_pool(\n",
    "                            conv, [1, 1, max_chars-width+1, 1],\n",
    "                            [1, 1, 1, 1], 'VALID')\n",
    "\n",
    "                    # activation\n",
    "                    conv = activation(conv)\n",
    "                    conv = tf.squeeze(conv, squeeze_dims=[2])\n",
    "\n",
    "                    convolutions.append(conv)\n",
    "\n",
    "            return tf.concat(convolutions, 2)\n",
    "\n",
    "        embedding = make_convolutions(self.char_embedding)\n",
    "\n",
    "        # for highway and projection layers\n",
    "        n_highway = cnn_options.get('n_highway')\n",
    "        use_highway = n_highway is not None and n_highway > 0\n",
    "        use_proj = n_filters != projection_dim\n",
    "\n",
    "        if use_highway or use_proj:\n",
    "            #   reshape from (batch_size, n_tokens, dim) to (-1, dim)\n",
    "            batch_size_n_tokens = tf.shape(embedding)[0:2]\n",
    "            embedding = tf.reshape(embedding, [-1, n_filters])\n",
    "\n",
    "        # set up weights for projection\n",
    "        if use_proj:\n",
    "            assert n_filters > projection_dim\n",
    "            with tf.variable_scope('CNN_proj') as scope:\n",
    "                    W_proj_cnn = tf.get_variable(\n",
    "                        \"W_proj\", [n_filters, projection_dim],\n",
    "                        initializer=tf.random_normal_initializer(\n",
    "                            mean=0.0, stddev=np.sqrt(1.0 / n_filters)),\n",
    "                        dtype=DTYPE)\n",
    "                    b_proj_cnn = tf.get_variable(\n",
    "                        \"b_proj\", [projection_dim],\n",
    "                        initializer=tf.constant_initializer(0.0),\n",
    "                        dtype=DTYPE)\n",
    "\n",
    "        # apply highways layers\n",
    "        def high(x, ww_carry, bb_carry, ww_tr, bb_tr):\n",
    "            carry_gate = tf.nn.sigmoid(tf.matmul(x, ww_carry) + bb_carry)\n",
    "            transform_gate = tf.nn.relu(tf.matmul(x, ww_tr) + bb_tr)\n",
    "            return carry_gate * transform_gate + (1.0 - carry_gate) * x\n",
    "\n",
    "        if use_highway:\n",
    "            highway_dim = n_filters\n",
    "\n",
    "            for i in range(n_highway):\n",
    "                with tf.variable_scope('CNN_high_%s' % i) as scope:\n",
    "                    W_carry = tf.get_variable(\n",
    "                        'W_carry', [highway_dim, highway_dim],\n",
    "                        # glorit init\n",
    "                        initializer=tf.random_normal_initializer(\n",
    "                            mean=0.0, stddev=np.sqrt(1.0 / highway_dim)),\n",
    "                        dtype=DTYPE)\n",
    "                    b_carry = tf.get_variable(\n",
    "                        'b_carry', [highway_dim],\n",
    "                        initializer=tf.constant_initializer(-2.0),\n",
    "                        dtype=DTYPE)\n",
    "                    W_transform = tf.get_variable(\n",
    "                        'W_transform', [highway_dim, highway_dim],\n",
    "                        initializer=tf.random_normal_initializer(\n",
    "                            mean=0.0, stddev=np.sqrt(1.0 / highway_dim)),\n",
    "                        dtype=DTYPE)\n",
    "                    b_transform = tf.get_variable(\n",
    "                        'b_transform', [highway_dim],\n",
    "                        initializer=tf.constant_initializer(0.0),\n",
    "                        dtype=DTYPE)\n",
    "\n",
    "                embedding = high(embedding, W_carry, b_carry,\n",
    "                                 W_transform, b_transform)\n",
    "\n",
    "        # finally project down if needed\n",
    "        if use_proj:\n",
    "            embedding = tf.matmul(embedding, W_proj_cnn) + b_proj_cnn\n",
    "\n",
    "        # reshape back to (batch_size, tokens, dim)\n",
    "        if use_highway or use_proj:\n",
    "            shp = tf.concat([batch_size_n_tokens, [projection_dim]], axis=0)\n",
    "            embedding = tf.reshape(embedding, shp)\n",
    "\n",
    "        # at last assign attributes for remainder of the model\n",
    "        self.embedding = embedding\n",
    "\n",
    "\n",
    "    def _build_word_embeddings(self):\n",
    "        projection_dim = self.options['lstm']['projection_dim']\n",
    "\n",
    "        # the word embeddings\n",
    "        with tf.device(\"/cpu:0\"):\n",
    "            self.embedding_weights = tf.get_variable(\n",
    "                \"embedding\", [self._n_tokens_vocab, projection_dim],\n",
    "                dtype=DTYPE,\n",
    "            )\n",
    "            self.embedding = tf.nn.embedding_lookup(self.embedding_weights,\n",
    "                                                self.ids_placeholder)\n",
    "\n",
    "\n",
    "    def _build_lstms(self):\n",
    "        # now the LSTMs\n",
    "        # these will collect the initial states for the forward\n",
    "        #   (and reverse LSTMs if we are doing bidirectional)\n",
    "\n",
    "        # parse the options\n",
    "        lstm_dim = self.options['lstm']['dim']\n",
    "        projection_dim = self.options['lstm']['projection_dim']\n",
    "        n_lstm_layers = self.options['lstm'].get('n_layers', 1)\n",
    "        cell_clip = self.options['lstm'].get('cell_clip')\n",
    "        proj_clip = self.options['lstm'].get('proj_clip')\n",
    "        use_skip_connections = self.options['lstm']['use_skip_connections']\n",
    "        if use_skip_connections:\n",
    "            print(\"USING SKIP CONNECTIONS\")\n",
    "        else:\n",
    "            print(\"NOT USING SKIP CONNECTIONS\")\n",
    "\n",
    "        # the sequence lengths from input mask\n",
    "        if self.use_character_inputs:\n",
    "            mask = tf.reduce_any(self.ids_placeholder > 0, axis=2)\n",
    "        else:\n",
    "            mask = self.ids_placeholder > 0\n",
    "        sequence_lengths = tf.reduce_sum(tf.cast(mask, tf.int32), axis=1)\n",
    "        batch_size = tf.shape(sequence_lengths)[0]\n",
    "\n",
    "        # for each direction, we'll store tensors for each layer\n",
    "        self.lstm_outputs = {'forward': [], 'backward': []}\n",
    "        self.lstm_state_sizes = {'forward': [], 'backward': []}\n",
    "        self.lstm_init_states = {'forward': [], 'backward': []}\n",
    "        self.lstm_final_states = {'forward': [], 'backward': []}\n",
    "\n",
    "        update_ops = []\n",
    "        for direction in ['forward', 'backward']:\n",
    "            if direction == 'forward':\n",
    "                layer_input = self.embedding\n",
    "            else:\n",
    "                layer_input = tf.reverse_sequence(\n",
    "                    self.embedding,\n",
    "                    sequence_lengths,\n",
    "                    seq_axis=1,\n",
    "                    batch_axis=0\n",
    "                )\n",
    "\n",
    "            for i in range(n_lstm_layers):\n",
    "                if projection_dim < lstm_dim:\n",
    "                    # are projecting down output\n",
    "                    lstm_cell = tf.nn.rnn_cell.LSTMCell(\n",
    "                        lstm_dim, num_proj=projection_dim,\n",
    "                        cell_clip=cell_clip, proj_clip=proj_clip)\n",
    "                else:\n",
    "                    lstm_cell = tf.nn.rnn_cell.LSTMCell(\n",
    "                            lstm_dim,\n",
    "                            cell_clip=cell_clip, proj_clip=proj_clip)\n",
    "\n",
    "                if use_skip_connections:\n",
    "                    # ResidualWrapper adds inputs to outputs\n",
    "                    if i == 0:\n",
    "                        # don't add skip connection from token embedding to\n",
    "                        # 1st layer output\n",
    "                        pass\n",
    "                    else:\n",
    "                        # add a skip connection\n",
    "                        lstm_cell = tf.nn.rnn_cell.ResidualWrapper(lstm_cell)\n",
    "\n",
    "                # collect the input state, run the dynamic rnn, collect\n",
    "                # the output\n",
    "                state_size = lstm_cell.state_size\n",
    "                # the LSTMs are stateful.  To support multiple batch sizes,\n",
    "                # we'll allocate size for states up to max_batch_size,\n",
    "                # then use the first batch_size entries for each batch\n",
    "                init_states = [\n",
    "                    tf.Variable(\n",
    "                        tf.zeros([self._max_batch_size, dim]),\n",
    "                        trainable=False\n",
    "                    )\n",
    "                    for dim in lstm_cell.state_size\n",
    "                ]\n",
    "                batch_init_states = [\n",
    "                    state[:batch_size, :] for state in init_states\n",
    "                ]\n",
    "\n",
    "                if direction == 'forward':\n",
    "                    i_direction = 0\n",
    "                else:\n",
    "                    i_direction = 1\n",
    "                variable_scope_name = 'RNN_{0}/RNN/MultiRNNCell/Cell{1}'.format(\n",
    "                    i_direction, i)\n",
    "                with tf.variable_scope(variable_scope_name):\n",
    "                    layer_output, final_state = tf.nn.dynamic_rnn(\n",
    "                        lstm_cell,\n",
    "                        layer_input,\n",
    "                        sequence_length=sequence_lengths,\n",
    "                        initial_state=tf.nn.rnn_cell.LSTMStateTuple(\n",
    "                            *batch_init_states),\n",
    "                    )\n",
    "\n",
    "                self.lstm_state_sizes[direction].append(lstm_cell.state_size)\n",
    "                self.lstm_init_states[direction].append(init_states)\n",
    "                self.lstm_final_states[direction].append(final_state)\n",
    "                if direction == 'forward':\n",
    "                    self.lstm_outputs[direction].append(layer_output)\n",
    "                else:\n",
    "                    self.lstm_outputs[direction].append(\n",
    "                        tf.reverse_sequence(\n",
    "                            layer_output,\n",
    "                            sequence_lengths,\n",
    "                            seq_axis=1,\n",
    "                            batch_axis=0\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "                with tf.control_dependencies([layer_output]):\n",
    "                    # update the initial states\n",
    "                    for i in range(2):\n",
    "                        new_state = tf.concat(\n",
    "                            [final_state[i][:batch_size, :],\n",
    "                             init_states[i][batch_size:, :]], axis=0)\n",
    "                        state_update_op = tf.assign(init_states[i], new_state)\n",
    "                        update_ops.append(state_update_op)\n",
    "    \n",
    "                layer_input = layer_output\n",
    "\n",
    "        self.mask = mask\n",
    "        self.sequence_lengths = sequence_lengths\n",
    "        self.update_state_op = tf.group(*update_ops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dump_token_embeddings function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_token_embeddings(vocab_file, options_file, weight_file, outfile):\n",
    "    '''\n",
    "    Given an input vocabulary file, dump all the token embeddings to the\n",
    "    outfile.  The result can be used as the embedding_weight_file when\n",
    "    constructing a BidirectionalLanguageModel.\n",
    "    '''\n",
    "    with open(options_file, 'r') as fin:\n",
    "        options = json.load(fin)\n",
    "    max_word_length = options['char_cnn']['max_characters_per_token']\n",
    "\n",
    "    vocab = UnicodeCharsVocabulary(vocab_file, max_word_length)\n",
    "    batcher = Batcher(vocab_file, max_word_length)\n",
    "\n",
    "    ids_placeholder = tf.placeholder('int32',\n",
    "                                     shape=(None, None, max_word_length)\n",
    "    )\n",
    "    model = BidirectionalLanguageModel(options_file, weight_file)\n",
    "    embedding_op = model(ids_placeholder)['token_embeddings']\n",
    "\n",
    "    n_tokens = vocab.size\n",
    "    embed_dim = int(embedding_op.shape[2])\n",
    "\n",
    "    embeddings = np.zeros((n_tokens, embed_dim), dtype=DTYPE)\n",
    "\n",
    "    config = tf.ConfigProto(allow_soft_placement=True)\n",
    "    with tf.Session(config=config) as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for k in range(n_tokens):\n",
    "            token = vocab.id_to_word(k)\n",
    "            char_ids = batcher.batch_sentences([[token]])[0, 1, :].reshape(\n",
    "                1, 1, -1)\n",
    "            embeddings[k, :] = sess.run(\n",
    "                embedding_op, feed_dict={ids_placeholder: char_ids}\n",
    "            )\n",
    "\n",
    "    with h5py.File(outfile, 'w') as fout:\n",
    "        ds = fout.create_dataset(\n",
    "            'embedding', embeddings.shape, dtype='float32', data=embeddings\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## weight_layers function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_layers(name, bilm_ops, l2_coef=None,\n",
    "                  use_top_only=False, do_layer_norm=False):\n",
    "    '''\n",
    "    Weight the layers of a biLM with trainable scalar weights to\n",
    "    compute ELMo representations.\n",
    "    For each output layer, this returns two ops.  The first computes\n",
    "        a layer specific weighted average of the biLM layers, and\n",
    "        the second the l2 regularizer loss term.\n",
    "    The regularization terms are also add to tf.GraphKeys.REGULARIZATION_LOSSES \n",
    "    Input:\n",
    "        name = a string prefix used for the trainable variable names\n",
    "        bilm_ops = the tensorflow ops returned to compute internal\n",
    "            representations from a biLM.  This is the return value\n",
    "            from BidirectionalLanguageModel(...)(ids_placeholder)\n",
    "        l2_coef: the l2 regularization coefficient $\\lambda$.\n",
    "            Pass None or 0.0 for no regularization.\n",
    "        use_top_only: if True, then only use the top layer.\n",
    "        do_layer_norm: if True, then apply layer normalization to each biLM\n",
    "            layer before normalizing\n",
    "    Output:\n",
    "        {\n",
    "            'weighted_op': op to compute weighted average for output,\n",
    "            'regularization_op': op to compute regularization term\n",
    "        }\n",
    "    '''\n",
    "    import h5py\n",
    "    def _l2_regularizer(weights):\n",
    "        if l2_coef is not None:\n",
    "            return l2_coef * tf.reduce_sum(tf.square(weights))\n",
    "        else:\n",
    "            return 0.0\n",
    "\n",
    "    # Get ops for computing LM embeddings and mask\n",
    "    lm_embeddings = bilm_ops['lm_embeddings']\n",
    "    mask = bilm_ops['mask']\n",
    "\n",
    "    n_lm_layers = int(lm_embeddings.get_shape()[1])\n",
    "    lm_dim = int(lm_embeddings.get_shape()[3])\n",
    "\n",
    "    with tf.control_dependencies([lm_embeddings, mask]):\n",
    "        # Cast the mask and broadcast for layer use.\n",
    "        mask_float = tf.cast(mask, 'float32')\n",
    "        broadcast_mask = tf.expand_dims(mask_float, axis=-1)\n",
    "\n",
    "        def _do_ln(x):\n",
    "            # do layer normalization excluding the mask\n",
    "            x_masked = x * broadcast_mask\n",
    "            N = tf.reduce_sum(mask_float) * lm_dim\n",
    "            mean = tf.reduce_sum(x_masked) / N\n",
    "            variance = tf.reduce_sum(((x_masked - mean) * broadcast_mask)**2\n",
    "                                    ) / N\n",
    "            return tf.nn.batch_normalization(\n",
    "                x, mean, variance, None, None, 1E-12\n",
    "            )\n",
    "\n",
    "        if use_top_only:\n",
    "            layers = tf.split(lm_embeddings, n_lm_layers, axis=1)\n",
    "            # just the top layer\n",
    "            sum_pieces = tf.squeeze(layers[-1], squeeze_dims=1)\n",
    "            # no regularization\n",
    "            reg = 0.0\n",
    "        else:\n",
    "            W = tf.get_variable(\n",
    "                '{}_ELMo_W'.format(name),\n",
    "                shape=(n_lm_layers, ),\n",
    "                initializer=tf.zeros_initializer,\n",
    "                regularizer=_l2_regularizer,\n",
    "                trainable=True,\n",
    "            )\n",
    "\n",
    "            # normalize the weights\n",
    "            normed_weights = tf.split(\n",
    "                tf.nn.softmax(W + 1.0 / n_lm_layers), n_lm_layers\n",
    "            )\n",
    "            # split LM layers\n",
    "            layers = tf.split(lm_embeddings, n_lm_layers, axis=1)\n",
    "    \n",
    "            # compute the weighted, normalized LM activations\n",
    "            pieces = []\n",
    "            for w, t in zip(normed_weights, layers):\n",
    "                if do_layer_norm:\n",
    "                    pieces.append(w * _do_ln(tf.squeeze(t, squeeze_dims=1)))\n",
    "                else:\n",
    "                    pieces.append(w * tf.squeeze(t, squeeze_dims=1))\n",
    "            sum_pieces = tf.add_n(pieces)\n",
    "    \n",
    "            # get the regularizer \n",
    "            reg = [\n",
    "                r for r in tf.get_collection(\n",
    "                                tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "                if r.name.find('{}_ELMo_W/'.format(name)) >= 0\n",
    "            ]\n",
    "            if len(reg) != 1:\n",
    "                raise ValueError\n",
    "\n",
    "        # scale the weighted sum by gamma\n",
    "        gamma = tf.get_variable(\n",
    "            '{}_ELMo_gamma'.format(name),\n",
    "            shape=(1, ),\n",
    "            initializer=tf.ones_initializer,\n",
    "            regularizer=None,\n",
    "            trainable=True,\n",
    "        )\n",
    "        weighted_lm_layers = sum_pieces * gamma\n",
    "\n",
    "        ret = {'weighted_op': weighted_lm_layers, 'regularization_op': reg}\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## begin to gen corpus token embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import json\n",
    "vocab_file = cur_dir+\"/dataset/vocab.txt\"\n",
    "options_file=cur_dir+'/model/options.json'\n",
    "weight_file=cur_dir+'/model/weights.hdf5'\n",
    "token_embedding_file = cur_dir+'/dataset/vocab_embedding.hdf5'\n",
    "predictive_options_file = cur_dir+\"/model/predictive_options.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(options_file, 'r') as f:\n",
    "    options = json.load(f)\n",
    "    \n",
    "options['char_cnn']['n_characters'] = 262 #用于预测的时候，需要把n_characters设置为262\n",
    "\n",
    "with open(os.path.join(cur_dir+'/model', 'predictive_options.json'), 'w') as fout:\n",
    "    fout.write(json.dumps(options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0725 23:49:39.111447 4630058432 deprecation.py:323] From <ipython-input-9-bfb6f2addf58>:443: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "W0725 23:49:39.136329 4630058432 deprecation.py:323] From <ipython-input-9-bfb6f2addf58>:488: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "W0725 23:49:39.237558 4630058432 deprecation.py:506] From /Users/jozee/miniconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USING SKIP CONNECTIONS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0725 23:49:39.867131 4630058432 deprecation.py:506] From /Users/jozee/miniconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py:961: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0725 23:49:40.740541 4630058432 deprecation.py:323] From /Users/jozee/miniconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py:244: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0725 23:49:44.359620 4630058432 deprecation.py:506] From /Users/jozee/miniconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py:180: calling squeeze (from tensorflow.python.ops.array_ops) with squeeze_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the `axis` argument instead\n"
     ]
    }
   ],
   "source": [
    "#dump_token_embeddings(vocab_file,predictive_options_file,weight_file,token_embedding_file)\n",
    "\n",
    "sentence = 'simplistic silly and tedious'\n",
    "tokenized_context = [sentence.split()]\n",
    "context_token_ids = tf.placeholder('int32', shape=(None, None))\n",
    "\n",
    "batcher = TokenBatcher(vocab_file)\n",
    "bilm = BidirectionalLanguageModel(\n",
    "    predictive_options_file,\n",
    "    weight_file,\n",
    "    use_character_inputs=False,\n",
    "    embedding_weight_file=token_embedding_file)\n",
    "\n",
    "context_embeddings_op = bilm(context_token_ids)\n",
    "\n",
    "elmo_context_input = weight_layers('input', context_embeddings_op, l2_coef=0.01)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    context_ids = batcher.batch_sentences(tokenized_context)\n",
    "    \n",
    "    elmoInputVec = sess.run(\n",
    "        [elmo_context_input['weighted_op']],\n",
    "        feed_dict={context_token_ids: context_ids})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[-0.04375371, -0.00655208,  0.05646587, ...,  0.02894705,\n",
      "          0.02893402,  0.03469059],\n",
      "        [-0.05793738, -0.01265648,  0.07482089, ..., -0.01911054,\n",
      "         -0.02036722,  0.00902181],\n",
      "        [-0.06579366, -0.03540128,  0.06532396, ..., -0.02355652,\n",
      "         -0.000296  ,  0.00608458],\n",
      "        [-0.03062164, -0.0099406 ,  0.0813665 , ..., -0.00179088,\n",
      "          0.00188247,  0.0110186 ]]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(elmoInputVec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
